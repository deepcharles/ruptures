@article{Truong2018,
archivePrefix = {arXiv},
arxivId = {1801.00718},
author = {Truong, C. and Oudre, L. and Vayatis, N.},
eprint = {1801.00718},
journal = {arXiv preprint arXiv:1801.00718},
pages = {1--31},
title = {{A review of change point detection}},
year = {2018}
}
@inproceedings{Xing2003,
author = {Xing, E. P. and Jordan, M. I. and Russell, S. J.},
booktitle = {Advances in Neural Information Processing Systems 21 (NIPS 2003)},
file = {:home/charles/Documents/Mendeley Desktop/2164-distance-metric-learning-with-application-to-clustering-with-side-information.pdf:pdf},
pages = {521--528},
title = {{Distance metric learning, with application to clustering with side-Information}},
year = {2003}
}
@article{Ross2015,
author = {Ross, G. J.},
file = {:home/charles/Documents/Mendeley Desktop/Parametric and Nonparametric Sequential Change Detection in R$\backslash$: The cpm Package.pdf:pdf},
journal = {Journal of Statistical Software},
number = {3},
title = {{Parametric and nonparametric sequential change detection in R: the cpm package}},
volume = {66},
year = {2015}
}
@article{James2015,
author = {James, N. A. and Matteson, D. S.},
file = {:home/charles/Documents/Mendeley Desktop/ecp$\backslash$: An R Package for Nonparametric Multiple Change Point Analysis of Multivariate Data.pdf:pdf},
journal = {Journal of Statistical Software},
number = {7},
title = {{ecp: an R package for nonparametric multiple change point analysis of multivariate data}},
volume = {62},
year = {2015}
}
@inproceedings{Hocking2015,
address = {Lille, France},
annote = {penalty learning},
author = {Hocking, T. and Rigaill, G. and Bourque, G.},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
file = {:home/charles/Documents/Mendeley Desktop/PeakSeg$\backslash$: constrained optimal segmentation and supervised penalty learning for peak detection in count data.pdf:pdf},
pages = {324--332},
title = {{PeakSeg: constrained optimal segmentation and supervised penalty learning for peak detection in count data}},
year = {2015}
}
@article{Haynes2017,
author = {Haynes, K. and Eckley, I. A. and Fearnhead, P.},
file = {:home/charles/Documents/Mendeley Desktop/Computationally efficient changepoint detection for a range of penalties.pdf:pdf},
journal = {Journal of Computational and Graphincal Statistics},
number = {1},
pages = {134--143},
title = {{Computationally efficient changepoint detection for a range of penalties}},
volume = {26},
year = {2017}
}
@article{Barrois-Muller2016a,
author = {Barrois-M{\"{u}}ller, R. and Ricard, D. and Oudre, L. and Tlili, L. and Provost, C. and Vienne, A. and Vidal, P.-P. and Buffat, S. and Yelnik, A.},
file = {:home/charles/Documents/Mendeley Desktop/{\'{E}}tude observationnelle du demi-tour {\`{a}} l'aide de capteurs inertiels chez les sujets victimes d'AVC et relation avec le risque de ch.pdf:pdf},
journal = {Neurophysiologie Clinique/Clinical Neurophysiology},
number = {4},
pages = {244},
title = {{{\'{E}}tude observationnelle du demi-tour {\`{a}} l'aide de capteurs inertiels chez les sujets victimes d'AVC et relation avec le risque de chute}},
volume = {46},
year = {2016}
}
@article{Maidstone2017,
author = {Maidstone, R. and Hocking, T. and Rigaill, G. and Fearnhead, P.},
file = {:home/charles/Documents/Mendeley Desktop/On optimal multiple changepoint algorithms for large data.pdf:pdf},
journal = {Statistics and Computing},
number = {2},
pages = {519--533},
title = {{On optimal multiple changepoint algorithms for large data}},
volume = {27},
year = {2017}
}
@article{Lavielle1999,
annote = {resultats th{\'{e}}oriques sur le dynamic programming.
hypoth{\`{e}}ses tr{\`{e}}s g{\'{e}}n{\'{e}}rales. Marche pour bruit d{\'{e}}pendent.},
author = {Lavielle, M.},
file = {:home/charles/Documents/Mendeley Desktop/Detection of multiples changes in a sequence of dependant variables.pdf:pdf},
journal = {Stochastic Processes and their Applications},
number = {1},
pages = {79--102},
title = {{Detection of multiples changes in a sequence of dependant variables}},
volume = {83},
year = {1999}
}
@book{Csorgo1997,
address = {Chichester, New York},
annote = {p-value asymptotique pour tester la pr{\'{e}}sence de ruptures.
monograph on change point detection.},
author = {Cs{\"{o}}rg{\"{o}}, M. and Horv{\'{a}}th, L.},
editor = {Wiley-Blackwell},
title = {{Limit theorems in change-point analysis}},
year = {1997}
}
@article{Aue2012,
annote = {eeg data
ar process},
author = {Aue, A. and Horv{\`{a}}th, L.},
file = {:home/charles/Documents/Mendeley Desktop/Structural breaks in time series.pdf:pdf},
journal = {Journal of Time Series Analysis},
pages = {1--16},
title = {{Structural breaks in time series}},
volume = {34},
year = {2012}
}
@article{Hinkley1970,
annote = {les index estim{\'{e}}s ne sont pas consistants.},
author = {Hinkley, D. V.},
journal = {Biometrika},
number = {1},
pages = {1--17},
title = {{Inference about the change point in a sequence of random variables}},
volume = {57},
year = {1970}
}
@phdthesis{Deshayes1983,
annote = {fractions de ruptures sont consistentes.},
author = {Deshayes, J. and Picard, D.},
school = {Universit{\'{e}} de Paris-Sud, Orsay, France},
title = {{Ruptures de mod{\`{e}}les en statistique}},
type = {In French},
year = {1983}
}
@article{Page1955,
annote = {premier article de detection de ruptures
constant par morceaux},
author = {Page, E. S.},
journal = {Biometrika},
pages = {523--527},
title = {{A test for a change in a parameter occurring at an unknown point}},
volume = {42},
year = {1955}
}
@article{Nam2012,
annote = {functional magnetic resonance imaging (fMRI) time series},
author = {Nam, C. F. H. and Aston, J. A. D. and Johansen, A. M.},
file = {:home/charles/Documents/Mendeley Desktop/Nam{\_}et{\_}al-2012-Journal{\_}of{\_}Time{\_}Series{\_}Analysis.pdf:pdf},
journal = {Journal of Time Series Analysis},
pages = {807--823},
title = {{Quantifying the uncertainty in change points}},
volume = {33},
year = {2012}
}
@article{Page1954,
annote = {premier article de detection de ruptures
constant par morceaux},
author = {Page, E. S.},
journal = {Biometrika},
pages = {100--105},
title = {{Continuous inspection schemes}},
volume = {41},
year = {1954}
}
@article{Lavielle1998,
annote = {AR par morceaux
EEG
penalit{\'{e}} lin{\'{e}}aire},
author = {Lavielle, M.},
file = {:home/charles/Documents/Mendeley Desktop/Optimal Segmentation of Random Processes.pdf:pdf},
journal = {IEEE Transactions on Signal Processing},
number = {5},
pages = {1365--1373},
title = {{Optimal segmentation of random processes}},
volume = {46},
year = {1998}
}
@article{Bai2010,
author = {Bai, J.},
journal = {Journal of Econometrics},
pages = {78--92},
title = {{Common breaks in means and variances for panel data}},
volume = {157},
year = {2010}
}
@article{Doyle2005,
annote = {variability and comovement of output, consumption, and investment in the G-7 economies},
author = {Doyle, B. M. and Faust, J.},
journal = {The Review of Economics and Statistics},
number = {4},
pages = {721--740},
title = {{Breaks in the variability and comovement of G-7 economic growth}},
volume = {87},
year = {2005}
}
@article{Paye2006,
annote = {data: stock return
ruptures dans les relations lineaires entre variables pr{\'{e}}dictives du stock return.},
author = {Paye, B. S. and Timmermann, A.},
journal = {Journal of Empirical Finance},
number = {3},
pages = {274--315},
title = {{Instability of return prediction models}},
volume = {13},
year = {2006}
}
@article{Bai1999,
author = {Bai, J.},
journal = {Journal of Econometrics},
pages = {299--323},
title = {{Likelihood ratio tests for multiple structural changes}},
volume = {91},
year = {1999}
}
@article{Bai2000,
author = {Bai, J.},
file = {:home/charles/Documents/Mendeley Desktop/Vector autoregressive models with structural changes in regression coefficients and in variance–covariance matrices.pdf:pdf},
journal = {Annals of Economics and Finance},
pages = {303--339},
title = {{Vector autoregressive models with structural changes in regression coefficients and in variance–covariance matrices}},
volume = {1},
year = {2000}
}
@article{Bai1995,
annote = {somme de valeurs absolues},
author = {Bai, J.},
journal = {Econometric Theory},
pages = {403--436},
title = {{Least absolute deviation of a shift}},
volume = {11},
year = {1995}
}
@article{Bai1994,
author = {Bai, J.},
journal = {Journal of Time Series Analysis},
pages = {453--472},
title = {{Least squares estimation of a shift in linear processes}},
volume = {15},
year = {1994}
}
@article{Bai1998b,
author = {Bai, J.},
journal = {Journal of Statistical Planning and Inference},
pages = {103--134},
title = {{Estimation of multiple-regime regressions with least absolutes deviation}},
volume = {74},
year = {1998}
}
@article{Bai1997a,
author = {Bai, J.},
journal = {Review of Economic and Statistics},
pages = {551--563},
title = {{Estimation of a change-point in multiple regression models}},
volume = {79},
year = {1997}
}
@article{Bai1996,
author = {Bai, J.},
journal = {Econometrica},
pages = {597--622},
title = {{Testing for parameter constancy in linear regressions: an empirical distribution function approach}},
volume = {64},
year = {1996}
}
@article{Angelosante2012,
annote = {cpd lasso l{\_}1
ar par morceaux
possibilit{\'{e}} d'adaptation pour OMP},
author = {Angelosante, D. and Giannakis, G. B.},
file = {:home/charles/Documents/Mendeley Desktop/Group lassoing change-points piece-constant AR processes.pdf:pdf},
journal = {EURASIP Journal on Advances in Signal Processing},
title = {{Group lassoing change-points piece-constant AR processes}},
url = {http://asp.eurasipjournals.com/content/2012/1},
volume = {70},
year = {2012}
}
@article{Ciuperca2014,
annote = {cpd avec penalit{\'{e}} l{\_}1 (lasso)},
author = {Ciuperca, G.},
file = {:home/charles/Documents/Mendeley Desktop/Model selection by LASSO methods in a change-point model.pdf:pdf},
journal = {Statistical Papers},
number = {2},
pages = {349--374},
title = {{Model selection by LASSO methods in a change-point model}},
volume = {55},
year = {2014}
}
@article{Bardwell2017,
annote = {hidden state variable: dernier index de rupture.
Deux {\'{e}}tats, normal ou anormal.},
author = {Bardwell, L. and Fearnhead, P.},
file = {:home/charles/Documents/Mendeley Desktop/Bayesian Detection of Abnormal Segments in Multiple Time Series.pdf:pdf},
journal = {Bayesian Analysis},
number = {1},
pages = {193--218},
title = {{Bayesian Detection of Abnormal Segments in Multiple Time Series}},
volume = {12},
year = {2017}
}
@article{Jandhyala2013,
annote = {review, surtout gaussian ou iid.
Plutot compl{\`{e}}te.},
author = {Jandhyala, V. and Fotopoulos, S. and Macneill, I. and Liu, P.},
file = {:home/charles/Documents/Mendeley Desktop/Inference for single and multiple change-points in time series.pdf:pdf},
journal = {Journal of Time Series Analysis},
pages = {423--446},
title = {{Inference for single and multiple change-points in time series}},
volume = {34},
year = {2013}
}
@article{Melnyk2017,
author = {Melnyk, I. and Banerjee, A.},
file = {:home/charles/Documents/Mendeley Desktop/A Spectral Algorithm for Inference in Hidden semi-Markov Models.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1--39},
title = {{A spectral algorithm for inference in hidden semi-Markov models}},
volume = {18},
year = {2017}
}
@article{Lavielle2001,
author = {Lavielle, M. and Lebarbier, E.},
file = {:home/charles/Documents/Mendeley Desktop/An application of MCMC methods for the multiple change-points problem.pdf:pdf},
journal = {Signal Processing},
number = {1},
pages = {39--53},
title = {{An application of MCMC methods for the multiple change-points problem}},
volume = {81},
year = {2001}
}
@article{Vostrikova1981,
annote = {first binary segmentation},
author = {Vostrikova, L. Y.},
journal = {Soviet Math. Dokl.},
pages = {55--59},
title = {{Detecting disorder in multidimensional random processes}},
volume = {24},
year = {1981}
}
@article{Olshen2004,
author = {Olshen, A. B. and Venkatraman, E. S. and Lucito, R. and Wigler, M.},
file = {:home/charles/Documents/Mendeley Desktop/Circular binary segmentation for the analysis of array-based DNA copy number data.pdf:pdf},
journal = {Biostatistics},
number = {4},
pages = {557--572},
title = {{Circular binary segmentation for the analysis of array-based DNA copy number data}},
volume = {5},
year = {2004}
}
@article{Yao1989,
author = {Yao, Y.-C. and Au, S. T.},
file = {:home/charles/Documents/Mendeley Desktop/Least-squares estimation of a step function.pdf:pdf},
journal = {Sankhyā: The Indian Journal of Statistics, Series A},
number = {3},
pages = {370--381},
title = {{Least-squares estimation of a step function}},
volume = {51},
year = {1989}
}
@article{Khodadadi2008,
annote = {suite d'abstracts en rapport avec la segmentation},
author = {Khodadadi, A. and Asgharian, M.},
file = {:home/charles/Documents/Mendeley Desktop/Change-point Problem and Regression- An Annotated Bibliography.pdf:pdf},
journal = {Collection of Biostatistics Research Archive (COBRA)},
title = {{Change-point problem and regression: an annotated bibliography}},
url = {http://biostats.bepress.com/cgi/viewcontent.cgi?article=1075{\&}context=cobra},
year = {2008}
}
@book{Scholkopf2002,
address = {Cambridge, USA},
author = {Sch{\"{o}}lkopf, B. and Smola, A. J.},
publisher = {MIT Press},
title = {{Learning with kernels}},
year = {2002}
}
@article{Lara2013,
author = {Lara, O. D. and Labrador, M. A.},
journal = {IEEE Communications Surveys {\&} Tutorials},
number = {3},
pages = {1192--1209},
title = {{A survey on human activity recognition using wearable sensors}},
volume = {15},
year = {2013}
}
@inproceedings{Seichepine2014,
address = {Florence, Italy},
author = {Seichepine, N. and Essid, S. and Fevotte, C. and Capp{\'{e}}, O.},
booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
file = {:home/charles/Documents/Mendeley Desktop/Piecewise constant nonnegative matrix factorization.pdf:pdf},
pages = {6721--6725},
title = {{Piecewise constant nonnegative matrix factorization}},
year = {2014}
}
@inproceedings{Karagiannaki2017,
address = {New Orleans, LA, USA},
annote = {sur le probl{\`{e}}me de "human activity recognition": il est difficile d'avoir des repr{\'{e}}sentations, mobile computing.},
author = {Karagiannaki, K. and Panousopoulou, A. and Tsakalides, P.},
booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
file = {:home/charles/Documents/Mendeley Desktop/AN ONLINE FEATURE SELECTION ARCHITECTURE FOR HUMAN ACTIVITY RECOGNITION.pdf:pdf},
pages = {2522--2526},
title = {{An online feature selection architecture for Human Activity Recognition}},
year = {2017}
}
@article{Ying2012,
author = {Ying, Y. and Li, P.},
file = {:home/charles/Documents/Mendeley Desktop/Distance Metric Learning with Eigenvalue Optimization .pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {metric learning,survey},
mendeley-tags = {metric learning,survey},
pages = {1--26},
title = {{Distance metric learning with eigenvalue optimization}},
volume = {13},
year = {2012}
}
@inproceedings{Oudre2015,
address = {Lyon, France},
author = {Oudre, L. and Moreau, T. and Truong, C.},
booktitle = {Proceedings of the Groupe de Recherche et d'Etudes en Traitement du Signal et des Images (GRETSI)},
title = {{D{\'{e}}tection de pas {\`{a}} partir de donn{\'{e}}es d'acc{\'{e}}l{\'{e}}rom{\'{e}}trie}},
year = {2015}
}
@inproceedings{Truong2017,
address = {Kos, Greece},
author = {Truong, C. and Oudre, L. and Vayatis, N.},
booktitle = {Proceedings of the European Signal Processing Conference (EUSIPCO)},
title = {{Penalty learning for changepoint detection}},
year = {2017}
}
@article{Barrois-Muller2015,
author = {Barrois-M{\"{u}}ller, R. and Oudre, L. and Moreau, T. and Truong, C. and Vayatis, N. and Buffat, S. and Yelnik, A. and de Waele, C. and Gregory, T. and Laporte, S. and Vidal, P. P. and Ricard, D.},
journal = {Computer Methods in Biomechanics and Biomedical Engineering},
pages = {1880--1881},
title = {{Quantify osteoarthritis gait at the doctor's office: a simple pelvis accelerometer based method independent from footwear and aging}},
volume = {18 Suppl 1},
year = {2015}
}
@article{Oudre2015a,
author = {Oudre, L. and Barrois-M{\"{u}}ller, R. and Moreau, T. and Truong, C. and Dadashi, R. and Gr{\'{e}}gory, T. and Ricard, D. and Vayatis, N. and {De Waele}, C. and Yelnik, A. and Vidal, P.-P.},
journal = {Neurophysiologie Clinique/Clinical Neurophysiology},
number = {4-5},
pages = {394},
title = {{D{\'{e}}tection automatique des pas {\`{a}} partir de capteurs inertiels pour la quantification de la marche en consultation}},
volume = {45},
year = {2015}
}
@article{Audiffren2015,
author = {Audiffren, J. and Barrois-M{\"{u}}ller, R. and Provost, C. and Chiarovano, {\'{E}}. and Oudre, L. and Moreau, T. and Truong, C. and Yelnik, A. and Vayatis, N. and Vidal, P.-P. and {De Waele}, C. and Buffat, S. and Ricard, D.},
journal = {Neurophysiologie Clinique/Clinical Neurophysiology},
number = {4-5},
pages = {403},
title = {{{\'{E}}valuation de l'{\'{e}}quilibre et pr{\'{e}}diction des risques de chutes en utilisant une Wii board balance}},
volume = {45},
year = {2015}
}
@article{Barrois-Muller2016,
author = {Barrois-M{\"{u}}ller, R. and Gregory, T. and Oudre, L. and Moreau, T. and Truong, C. and {Aram Pulini}, A. and Vienne, A. and Labourdette, C. and Vayatis, N. and Buffat, S. and Yelnik, A. and de Waele, C. and Laporte, S. and Vidal, P.-P. and Ricard, D.},
journal = {PLoS One},
number = {10},
pages = {e0164975},
title = {{An automated recording method in clinical consultation to rate the limp in lower limb osteoarthritis}},
volume = {11},
year = {2016}
}
@inproceedings{Truong2015,
address = {Lyon, France},
author = {Truong, C. and Oudre, L. and Vayatis, N.},
booktitle = {Proceedings of the Groupe de Recherche et d'Etudes en Traitement du Signal et des Images (GRETSI)},
title = {{Segmentation de signaux physiologiques par optimisation globale}},
year = {2015}
}
@incollection{Lavielle2007,
address = {Berlin, Germany},
annote = {sup{\'{e}}riorit{\'{e}} de la m{\'{e}}thode exacte face aux arbres.},
author = {Lavielle, M. and Teyssi{\`{e}}re, G.},
booktitle = {Long-Memory in Economics},
editor = {Teyssi{\`{e}}re, G. and Kirman, A. P.},
file = {:home/charles/Documents/Mendeley Desktop/Adaptive Detection of Multiple Change-Points in Asset Price Volatility.pdf:pdf},
pages = {129--156},
publisher = {Springer Verlag},
title = {{Adaptive detection of multiple change-points in asset price volatility}},
year = {2007}
}
@article{Lung-Yut-Fong2012,
annote = {dynamic programming
test d'homog{\'{e}}n{\'{e}}it{\'{e}}
ranking},
author = {Lung-Yut-Fong, A. and L{\'{e}}vy-Leduc, C. and Capp{\'{e}}, O.},
file = {:home/charles/Documents/Mendeley Desktop/DISTRIBUTED DETECTION LOCALIZATION OF CHANGE-POINTS INHIGH-DIMENSIONAL NETWORK TRAFFIC DATA.pdf:pdf},
journal = {Statistics and Computing},
number = {2},
pages = {485--496},
title = {{Distributed detection/localization of change-points in high-dimensional network traffic data}},
volume = {22},
year = {2012}
}
@book{Darkhovsky1993,
annote = {on peut se ramener au cas constant par morceaux.},
author = {Brodsky, B. E. and Darkhovsky, B. S.},
file = {:home/charles/Documents/Mendeley Desktop/Nonparametric Methods in Change-Point Problems (1993).pdf:pdf},
publisher = {Springer Netherlands},
title = {{Nonparametric methods in change point problems}},
year = {1993}
}
@article{Bai1997,
annote = {asymptotic consistency of sequential estimation.},
author = {Bai, J.},
file = {:home/charles/Documents/Mendeley Desktop/1997{\_}Estimating{\_}multiple{\_}breaks{\_}one{\_}at{\_}a{\_}time.pdf:pdf},
journal = {Econometric Theory},
number = {3},
pages = {315--352},
title = {{Estimating multiple breaks one at a time}},
volume = {13},
year = {1997}
}
@article{Donoho2001,
author = {Donoho, D. L. and Huo, X.},
file = {:home/charles/Documents/Mendeley Desktop/Uncertainty principles and ideal atomic decomposition.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {7},
pages = {2845--2862},
title = {{Uncertainty principles and ideal atomic decomposition}},
volume = {47},
year = {2001}
}
@article{Gribonval2008,
author = {Gribonval, R. and Rauhut, H. and Schnass, K. and Vandergheynst, P.},
file = {:home/charles/Documents/Mendeley Desktop/Atoms of all channels, unite! Average case analysis of multi-channel sparse recovery using greedy algorithms.pdf:pdf},
journal = {Journal of Fourier Analysis and Applications},
keywords = {Average analysis,Greedy algorithms,Multi-channel,OMP,Thresholding},
number = {5},
pages = {655--687},
title = {{Atoms of all channels, unite! Average case analysis of multi-channel sparse recovery using greedy algorithms}},
volume = {14},
year = {2008}
}
@article{Harchaoui2010a,
author = {Harchaoui, Z. and L{\'{e}}vy-Leduc, C.},
file = {:home/charles/Documents/Mendeley Desktop/Multiple Change-Point Estimation Witha Total Variation Penalty.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {492},
pages = {1480--1493},
title = {{Multiple Change-Point Estimation With a Total Variation Penalty}},
volume = {105},
year = {2010}
}
@article{Cai2011,
author = {Cai, T. and Wang, L.},
file = {:home/charles/Documents/Mendeley Desktop/Orthogonal Matching Pursuit for Sparse Signal Recovery With Noise.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {7},
pages = {4680--4688},
title = {{Orthogonal Matching Pursuit for Sparse Signal Recovery With Noise}},
volume = {57},
year = {2011}
}
@article{Wang2012,
author = {Wang, J. and Shim, B.},
file = {:home/charles/Documents/Mendeley Desktop/On the Recovery Limit of Sparse Signals using Orthogonal Matching Pursuit.pdf:pdf},
journal = {IEEE Transactions on Signal Processing},
number = {9},
pages = {4973--4976},
title = {{On the Recovery Limit of Sparse Signals using Orthogonal Matching Pursuit}},
volume = {60},
year = {2012}
}
@article{Lavielle2000a,
author = {Lavielle, M. and Moulines, E.},
file = {:home/charles/Documents/Mendeley Desktop/Least-squares estimation of an unknown number of shifts in a time series.pdf:pdf},
journal = {Journal of Time Series Analysis},
number = {1},
pages = {33--59},
title = {{Least‐squares Estimation of an Unknown Number of Shifts in a Time Series}},
volume = {21},
year = {2000}
}
@article{Tropp2004,
author = {Tropp, J. A.},
file = {:home/charles/Documents/Mendeley Desktop/GREED IS GOOD$\backslash$: ALGORITHMIC RESULTS FOR SPARSE APPROXIMATION.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {10},
pages = {2231--2242},
title = {{Greed is good: Algorithmic results for sparse approximation}},
volume = {50},
year = {2004}
}
@article{Herzet2013,
author = {Herzet, C. and Soussen, C. and Idier, J. and Gribonval, R.},
file = {:home/charles/Documents/Mendeley Desktop/Exact recovery conditions for sparse representations with partial support information.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {11},
pages = {7509--7524},
title = {{Exact Recovery Conditions for Sparse Representations with Partial Support Information}},
volume = {59},
year = {2013}
}
@article{Davenport2010,
author = {Davenport, M. A. and Wakin, M. B.},
file = {:home/charles/Documents/Mendeley Desktop/Analysis of Orthogonal Matching Pursuit Using the Restricted Isometry Property.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {9},
pages = {4395--4401},
title = {{Analysis of Orthogonal Matching Pursuit Using the Restricted Isometry Property}},
volume = {56},
year = {2010}
}
@article{Davis1997,
author = {Davis, G. and Mallat, S. and Avellaneda, M.},
file = {:home/charles/Documents/Mendeley Desktop/Davis, Mallat, Avellaneda - 1997 - No Adaptive Greedy Approximations.pdf:pdf},
journal = {Constructive Approximation},
number = {1},
pages = {57--98},
title = {{Adaptive Greedy Approximations}},
volume = {13},
year = {1997}
}
@book{Kay1993,
author = {Kay, S. M. and Oppenheim, A. V.},
publisher = {Prentice Hall},
title = {{Fundamentals of Statistical Signal Processing, Volume II: Detection Theory}},
year = {1993}
}
@inproceedings{Keogh2001,
author = {Keogh, E. and Chu, S. and Hart, D. and Pazzani, M.},
booktitle = {Proceedings of the IEEE International Conference on Data Mining (ICDM)},
file = {:home/charles/Documents/Mendeley Desktop/An Online Algorithm for Segmenting Time Series.pdf:pdf},
pages = {289--296},
title = {{An online algorithm for segmenting time series}},
year = {2001}
}
@article{Harchaoui2012,
author = {Harchaoui, Z. and L{\'{e}}vy-Leduc, C.},
file = {:home/charles/Documents/Mendeley Desktop/Harchaoui, L{\'{e}}vy-Leduc - 2012 - Multiple change-point estimation with a total variation penalty.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {492},
pages = {1480--1493},
title = {{Multiple change-point estimation with a total variation penalty}},
volume = {105},
year = {2010}
}
@article{Lorden1971,
author = {Lorden, G.},
file = {:home/charles/Documents/Mendeley Desktop/Procedures for Reacting to a Change in Distribution.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
number = {6},
pages = {1897--1908},
title = {{Procedures for Reacting to a Change in Distribution}},
volume = {42},
year = {1971}
}
@article{Lavielle2000,
abstract = {In this contribution, general results on the o -line least-squares estimate of changes in the mean of a random process are presented. First, a generalisation of the Hajek-Renyi inequality, dealing with the uctuations of the normalized partial sums, is given. This preliminary result is then used to derive the consistency and the rate of convergence of the change-points estimate, in the situation where the number of changes is known. Strong consistency is obtained under some mixing conditions. The limiting distribution is also computed under an invariance principle. The case where the number of changes is unknown is then addressed. All these results apply to a large class of dependent processes, including strongly mixing and also long-range dependent processes.},
annote = {convergence des breakpoint fractions avec nb de ruptures connu.
Avec penalit{\'{e}} lin{\'{e}}aire, c'est pareil. La taille des segments grandit lin{\'{e}}airement avec le nb d'{\'{e}}chantillons.},
author = {Lavielle, M. and Moulines, E.},
file = {:home/charles/Documents/Mendeley Desktop/Least-squares estimation of an unknown number of shifts in a time series.pdf:pdf},
journal = {Journal of Time Series Analysis},
number = {1},
pages = {33--59},
title = {{Least-squares estimation of an unknown number of shifts in a time series}},
volume = {21},
year = {2000}
}
@inproceedings{Harchaoui2009,
address = {Taipei, Taiwan},
author = {Harchaoui, Z. and Vallet, F. and Lung-Yut-Fong, A. and Capp{\'{e}}, O.},
booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
file = {:home/charles/Documents/Mendeley Desktop/A{\_}regularized{\_}kernel-based{\_}approach{\_}to{\_}unsupervise.pdf:pdf},
pages = {1665--1668},
title = {{A regularized kernel-based approach to unsupervised audio segmentation}},
year = {2009}
}
@article{Arlot2010,
annote = {cross validation pour change point detection},
author = {Arlot, S. and Celisse, A.},
file = {:home/charles/Documents/Mendeley Desktop/A survey of cross-validation procedures for model selection.pdf:pdf},
journal = {Statistical Surveys},
pages = {40--79},
title = {{A survey of cross-validation procedures for model selection}},
volume = {4},
year = {2010}
}
@article{Mallows1973,
abstract = {We discuss the interpretation of CP-plots and show how they can be calibrated in several ways. We comment on the practice of using the display as a basis for formal selection of a subset-regression model, and extend the range of application of the device to encompass arbitrary linear estimates of the regression coefficients, for example Ridge estimates.},
author = {Mallows, C. L.},
journal = {Technometrics},
number = {4},
pages = {661--675},
title = {{Some comments on Cp}},
volume = {15},
year = {1973}
}
@inproceedings{Oudre2011,
abstract = {This paper describes a method for segmentation of triaxial accelerometer signals recorded during continuous treadmill walking. More specifically, we aim at detecting changes in speed and in incline by analyzing the accelerometer signals recorded on the shin or the waist of the walker. The raw accelerometer signals are transformed either in the time-frequency domain (with a Short-Time Fourier Transform) or in a specific features space (which emphasizes the characteristics of the gait). The transformed signals serve as inputs for change-point detection methods which output a number of estimated change times. Several change-point detection methods are tested, either parametric or non-parametric. In particular, a new change-point detection method is introduced, which takes into account the frequency structure of walking signals. The different signal representations and change-points detection methods are evaluated on a corpus of 24 subjects. An analysis of the obtained results is presented for the two considered sensors (waist and shin).},
author = {Oudre, L. and Lung-Yut-Fong, A. and Bianchi, P.},
booktitle = {Proceedings of the 19th European Signal Processing Conference (EUSIPCO)},
file = {:home/charles/Documents/Mendeley Desktop/SEGMENTATION OF ACCELEROMETER SIGNALS RECORDED DURING CONTINUOUS TREADMILL WALKING.pdf:pdf},
pages = {1564--1568},
title = {{Segmentation of accelerometer signals recorded during continuous treadmill walking}},
year = {2011}
}
@article{Picard2005,
abstract = {Microarray-CGH experiments are used to detect and map chromosomal imbalances, by hybridizing targets of genomic DNA from a test and a reference sample to sequences immobilized on a slide. These probes are genomic DNA sequences (BACs) that are mapped on the genome. The signal has a spatial coherence that can be handled by specific statistical tools. Segmentation methods seem to be a natural framework for this purpose. A CGH profile can be viewed as a succession of segments that represent homogeneous regions in the genome whose BACs share the same relative copy number on average. We model a CGH profile by a random Gaussian process whose distribution parameters are affected by abrupt changes at unknown coordinates. Two major problems arise : to determine which parameters are affected by the abrupt changes (the mean and the variance, or the mean only), and the selection of the number of segments in the profile.},
annote = {penalized methods on CGH profiles.},
author = {Picard, F. and Robin, S. and Lavielle, M. and Vaisse, C. and Daudin, J.-J.},
doi = {10.1186/1471-2105-6-27},
file = {:home/charles/Documents/Mendeley Desktop/A statistical approach for array CGH data analysis.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {27},
title = {{A statistical approach for array CGH data analysis}},
url = {http://dx.doi.org/10.1186/1471-2105-6-27},
volume = {6},
year = {2005}
}
@article{Friedman1991,
abstract = {A new method is presented for flexible regression modeling of high dimensional data. The model takes the form of an expansion in product spline basis functions, where the number of basis functions as well as the parameters associated with each one (product degree and knot locations) are automatically determined by the data. This procedure is motivated by the recursive partitioning approach to regression and shares its attractive properties. Unlike recursive partitioning, however, this method produces continuous models with continuous derivatives. It has more power and flexibility to model relationships that are nearly additive or involve interactions in at most a few variables. In addition, the model can be represented in a form that separately identifies the additive contributions and those associated with the different multivariable interactions.},
author = {Friedman, Jerome H.},
file = {:home/charles/Documents/Mendeley Desktop/MULTIVARIATE ADAPTIVE REGRESSION.pdf:pdf},
journal = {The Annals of Statistics},
number = {1},
pages = {1--67},
title = {{Multivariate Adaptive Regression Splines}},
volume = {19},
year = {1991}
}
@book{Nocedal2006,
address = {New York},
author = {Nocedal, J. and Wright, S.},
edition = {2},
publisher = {Springer-Verlag New York},
title = {{Numerical Optimization}},
year = {2006}
}
@article{lbfgs,
author = {Byrd, R. and Lu, P. and Nocedal, J. and Zhu, C.},
journal = {SIAM Journal on Scientific Computing},
number = {5},
pages = {1190--1208},
title = {{A Limited Memory Algorithm for Bound Constrained Optimization}},
volume = {16},
year = {1995}
}
@article{Maidstone2016,
author = {Maidstone, R and Hocking, T. and Rigaill, G. and Fearnhead, P.},
journal = {Statistics and Computing},
pages = {1--15},
title = {{On optimal multiple changepoint algorithms for large data}},
url = {3},
year = {2016}
}
@article{Boysen2009,
author = {Boysen, L. and Kempe, A. and Liebscher, V. and Munk, A. and Wittich, O.},
file = {:home/charles/Documents/Mendeley Desktop/Boysen et al. - 2009 - Consistencies and rates of convergence of jump-penalized least squares estimators.pdf:pdf},
journal = {The Annals of Statistics},
number = {1},
pages = {157--183},
title = {{Consistencies and rates of convergence of jump-penalized least squares estimators}},
volume = {37},
year = {2009}
}
@book{ORuanaidh1996,
annote = {pour citer une application en oil{\&}gas (well log data{\`{a}}},
author = {{O Ruanaidh}, Joseph J.K. and Fitzgerald, William J.},
edition = {1},
publisher = {Springer-Verlag New York},
title = {{Numerical Bayesian Methods Applied to Signal Processing}},
year = {1996}
}
@article{Chen1997,
annote = {application en finance},
author = {Chen, Jie and Gupta, A. K.},
doi = {10.1198/016214507000000932},
file = {:home/charles/Documents/Mendeley Desktop/Chen, Gupta - 1997 - Testing and Locating Variance Changepoints with Application to Stock Prices.pdf:pdf},
isbn = {0162145070000},
journal = {Journal of the American Statistical Association},
number = {438},
pages = {739747},
title = {{Testing and Locating Variance Changepoints with Application to Stock Prices}},
volume = {92},
year = {1997}
}
@article{Martinez2014,
author = {Mart{\'{i}}nez, Asael Fabian and Mena, Rams{\'{e}}s H.},
doi = {10.1214/14-BA878},
file = {:home/charles/Documents/Mendeley Desktop/On a Nonparametric Change Point Detection Model in Markovian Regimes.pdf:pdf},
issn = {19316690},
journal = {Bayesian Analysis},
keywords = {Bayesian nonparametric,Change point detection,Ornstein-Uhlenbeck process,Two-parameter Poisson-Dirichlet process},
number = {4},
pages = {823--858},
title = {{On a Nonparametric Change Point Detection Model in Markovian Regimes}},
volume = {9},
year = {2014}
}
@incollection{Kaplan2000,
address = {Dordrecht (the Netherlands)},
annote = {pour citer un papier sur l'utilisation en m{\'{e}}decine},
author = {Kaplan, A. Y. and Shishkin, S. L.},
booktitle = {Nonparametric Statistical Diagnosis: Problems and Methods},
chapter = {7},
editor = {Brodsky, B. E. and Darkhovsky, B. S.},
pages = {333--388},
publisher = {Kluwer Academic Publishers},
title = {{Application of the change-point analysis to the investigation of the brain's electrical activity}},
year = {2000}
}
@book{Chen2011a,
annote = {{\'{e}}tat de l'art
(que de la binary segmentation et du constant par morceaux)},
author = {Chen, J. and Gupta, A. K.},
booktitle = {Birkhauser},
edition = {2},
file = {:home/charles/Documents/Mendeley Desktop/Chen, Gupta - 2011 - Parametric Statistical Change Point Analysis With Applications to Genetics, Medicine, and Finance.pdf:pdf},
title = {{Parametric Statistical Change Point Analysis: With Applications to Genetics, Medicine, and Finance}},
year = {2011}
}
@article{Barry1993,
annote = {Article sur m{\'{e}}thode bay{\'{e}}sienne
bon journal, article tr{\`{e}}s cit{\'{e}}
impl{\'{e}}mentation R},
author = {Barry, Daniel and Hartigan, J. A.},
doi = {10.1198/016214507000000932},
file = {:home/charles/Documents/Mendeley Desktop/Barry, Hartigan - 1993 - A Bayesian Analysis for Change Point Problems.pdf:pdf},
isbn = {0471109916},
journal = {Journal of the American Statistical Association},
number = {421},
pages = {309--319},
title = {{A Bayesian Analysis for Change Point Problems}},
volume = {88},
year = {1993}
}
@article{Fearnhead2006,
abstract = {We demonstrate how to perform direct simulation from the posterior distribution of a class of multiple changepoint models where the number of changepoints is unknown. The class of models assumes independence between the posterior distribution of the parameters associated with segments of data between successive changepoints. This approach is based on the use of recursions, and is related to work on product partition models. The computational complexity of the approach is quadratic in the number of observations, but an approximate version, which introduces negligible error, and whose computational cost is roughly linear in the number of observations, is also possible. Our approach can be useful, for example within an MCMC algorithm, even when the independence assumptions do not hold. We demonstrate our approach on coal-mining disaster data and on well-log data. Our method can cope with a range of models, and exact simulation from the posterior distribution is possible in a matter of minutes.},
annote = {article tr{\`{e}}s cit{\'{e}} et dans un bon journal sur une m{\'{e}}thode bayesienne},
author = {Fearnhead, Paul},
doi = {10.1007/s11222-006-8450-8},
file = {:home/charles/Documents/Mendeley Desktop/Fearnhead - 2006 - Exact and efficient Bayesian inference for multiple changepoint problems.pdf:pdf},
isbn = {1122200684},
issn = {09603174},
journal = {Statistics and Computing},
keywords = {Bayes factor,Forward-backward algorithm,Model choice,Perfect simulation,Reversible jump MCMC,Well-log data},
number = {2},
pages = {203--213},
pmid = {20919347},
title = {{Exact and efficient Bayesian inference for multiple changepoint problems}},
volume = {16},
year = {2006}
}
@article{Fryzlewicz2007,
annote = {bottom up et top down, {\`{a}} base d'ondelettes
impl{\'{e}}mentation R
bon journal
constant par morceaux
un param{\`{e}}tre {\`{a}} tuner},
author = {Fryzlewicz, Piotr},
doi = {10.1198/016214507000000860},
file = {:home/charles/Documents/Mendeley Desktop/Fryzlewicz - 2007 - Unbalanced Haar Technique for Nonparametric Function Estimation.pdf:pdf},
isbn = {0162145070000},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {binary segmentation,cart,matching,smooting},
number = {480},
pages = {1318--1327},
title = {{Unbalanced Haar Technique for Nonparametric Function Estimation}},
volume = {102},
year = {2007}
}
@article{Barry1992,
annote = {Article sur m{\'{e}}thode bay{\'{e}}sienne
bon journal, article tr{\`{e}}s cit{\'{e}}
impl{\'{e}}mentation R},
author = {Barry, Daniel and Hartigan, J. A.},
doi = {10.1214/09-STS284},
file = {:home/charles/Documents/Mendeley Desktop/Barry, Hartigan - 1992 - Product Partition Models for Change Point Problems.pdf:pdf},
isbn = {0940600315},
journal = {The Annals of Statistics},
number = {1},
pages = {260--279},
title = {{Product Partition Models for Change Point Problems}},
volume = {20},
year = {1992}
}
@article{Zhang2007,
abstract = {In the analysis of data generated by change-point processes, one critical challenge is to determine the number of change-points. The classic Bayes information criterion (BIC) statistic does not work well here because of irregularities in the likelihood function. By asymptotic approximation of the Bayes factor, we derive a modified BIC for the model of Brownian motion with changing drift. The modified BIC is similar to the classic BIC in the sense that the first term consists of the log likelihood, but it differs in the terms that penalize for model dimension. As an example of application, this new statistic is used to analyze array-based comparative genomic hybridization (array-CGH) data. Array-CGH measures the number of chromosome copies at each genome location of a cell sample, and is useful for finding the regions of genome deletion and amplification in tumor cells. The modified BIC performs well compared to existing methods in accurately choosing the number of regions of changed copy number. Unlike existing methods, it does not rely on tuning parameters or intensive computing. Thus it is impartial and easier to understand and to use.},
author = {Zhang, N. R. and Siegmund, D. O.},
doi = {10.1111/j.1541-0420.2006.00662.x},
file = {:home/charles/Documents/Mendeley Desktop/Zhang, Siegmund - 2007 - A modified Bayes information criterion with applications to the analysis of comparative genomic hybridization d.pdf:pdf},
isbn = {0006-341X (Print)$\backslash$r0006-341X (Linking)},
journal = {Biometrics},
keywords = {Bayes information criterion,Change-point,Comparative genomic hybridization,Model selection},
number = {1},
pages = {22--32},
pmid = {17447926},
title = {{A modified Bayes information criterion with applications to the analysis of comparative genomic hybridization data.}},
volume = {63},
year = {2007}
}
@article{Yao1988,
author = {Yao, Y.-C.},
file = {:home/charles/Documents/Mendeley Desktop/Yao - 1988 - Estimating the number of change-points via Schwarz' criterion.pdf:pdf},
journal = {Statistics and Probability Letters},
number = {3},
pages = {181--189},
title = {{Estimating the number of change-points via Schwarz' criterion}},
volume = {6},
year = {1988}
}
@article{Lavielle2005,
author = {Lavielle, M.},
file = {:home/charles/Documents/Mendeley Desktop/Lavielle - 2005 - Using penalized contrasts for the change-point problem.pdf:pdf},
journal = {Signal Processing},
number = {8},
pages = {1501--1510},
title = {{Using penalized contrasts for the change-point problem}},
volume = {85},
year = {2005}
}
@inproceedings{harchaoui2008nips,
address = {Vancouver, Canada},
author = {Harchaoui, Z. and Bach, F. and Moulines, E.},
booktitle = {Advances in Neural Information Processing Systems 21 (NIPS 2008)},
file = {:home/charles/Documents/Mendeley Desktop/Kernel Change-point Analysis.pdf:pdf},
pages = {609--616},
title = {{Kernel Change-point Analysis}},
year = {2008}
}
@article{Chernoff1964,
author = {Chernoff, H and Zacks, S},
file = {:home/charles/Documents/Mendeley Desktop/Chernoff, Zacks - 1964 - Estimating the Current Mean of a Normal Distribution which is Subjected to Changes in Time.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
number = {3},
pages = {999--1018},
title = {{Estimating the Current Mean of a Normal Distribution which is Subjected to Changes in Time}},
url = {http://www.jstor.org/stable/2238232},
volume = {35},
year = {1964}
}
@article{Krishnaiah1988,
annote = {mean shift, point de vue statistiqique.},
author = {Krishnaiah, P. R.},
journal = {Handbook of Statistics},
pages = {375--402},
title = {{Review about estimation of change points}},
volume = {7},
year = {1988}
}
@article{Zacks1983,
author = {Zacks, S.},
file = {:home/charles/Documents/Mendeley Desktop/Zacks - 1983 - Survey of classical and Bayesian approaches to the change-point problem fixed sample and sequential procedures of testing.pdf:pdf},
journal = {Recent Advances in Statistics},
pages = {245--269},
title = {{Survey of classical and Bayesian approaches to the change-point problem: fixed sample and sequential procedures of testing and estimation}},
volume = {25},
year = {1983}
}
@incollection{Bhattacharya1994,
annote = {{\'{e}}tude th{\'{e}}orique: mean shift et rupture lin{\'{e}}raire.
Test statistique, vitesse de convergence des param{\`{e}}tres (et de l'instant de rupture?)},
author = {Bhattacharya, P. K.},
booktitle = {Change-point problems},
doi = {10.1214/lnms/1215463112},
edition = {23},
editor = {Carlstein, Edward and M{\"{u}}ller, Hans-Georg and Siegmund, David},
file = {:home/charles/Documents/Mendeley Desktop/Bhattacharya - 1994 - Some Aspects of Change-point Analysis.pdf:pdf},
pages = {28--56},
publisher = {Institute of Mathematical Statistics},
title = {{Some Aspects of Change-point Analysis}},
year = {1994}
}
@article{fryzlewicz2014,
annote = {binary segmentation am{\'{e}}lior{\'{e}}e

Les articles de l'{\'{e}}tat de l'art cit{\'{e}}s sont {\`{a}} reprendre.},
author = {Fryzlewicz, P.},
doi = {10.1214/14-AOS1245},
file = {:home/charles/Documents/Mendeley Desktop/Fryzlewicz - 2014 - Wild binary segmentation for multiple change-point detection.pdf:pdf},
journal = {The Annals of Statistics},
number = {6},
pages = {2243--2281},
publisher = {The Institute of Mathematical Statistics},
title = {{Wild binary segmentation for multiple change-point detection}},
volume = {42},
year = {2014}
}
@article{Srivastava75binseg,
abstract = {Procedures are considered for testing whether the means of each variable in a sequence of independent random variables can be taken to be the same, against alternatives that a shift might have occurred after some point r. Bayesian test statistics as well as some statistics depending on estimates of r are presented and their powers compared. Exact and asymptotic distribution functions are derived for some of the Bayesian statistics.},
annote = {binary search},
author = {{Ashish Sen}, Muni S Srivastava},
doi = {10.2307/2958081},
file = {:home/charles/Documents/Mendeley Desktop/Ashish Sen - 1975 - On Tests for Detecting Change in Mean.pdf:pdf},
issn = {00905364},
journal = {The Annals of Statistics},
number = {1},
pages = {98--108},
publisher = {Institute of Mathematical Statistics},
title = {{On Tests for Detecting Change in Mean}},
url = {http://www.jstor.org/stable/2958081},
volume = {3},
year = {1975}
}
@article{Frick2014,
author = {Frick, K. and Munk, A. and Sieling, H.},
file = {:home/charles/Documents/Mendeley Desktop/Frick, Munk, Sieling - 2014 - Multiscale change point inference.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Change point regression,Dynamic programming,Exponential families,Honest confidence sets,Multiscale methods},
number = {3},
pages = {495--580},
title = {{Multiscale change point inference}},
volume = {76},
year = {2014}
}
@inproceedings{989520,
annote = {binary segmentation
constant par morceaux},
author = {Himberg, J. and Korpiaho, K. and Mannila, H. and Tikanmaki, J. and Toivonen, H. T. T.},
booktitle = {Proceedings of the IEEE International Conference on Data Mining (ICDM)},
doi = {10.1109/ICDM.2001.989520},
file = {:home/charles/Documents/Mendeley Desktop/Himberg et al. - 2001 - Time series segmentation for context recognition in mobile devices.pdf:pdf},
keywords = {Acceleration,Algorithm design and analysis,Context awareness,Cost function,Dynamic programming,Humidity,Laboratories,Mobile communication,Mobile handsets,Noise level,acceleration,adaptive personalized user interface,cellular radio,context recognition,dynamic programming,global iterative replacement,humidity,luminosity,minimized intrasegment variances,mobile devices,mobile phone applications,noise level,randomized algorithm,sensor data,sensor fusion,time series,time series segmentation,user interfaces},
pages = {203--210},
title = {{Time series segmentation for context recognition in mobile devices}},
year = {2001}
}
@incollection{CBO9780511984679A085,
annote = {{\'{e}}tat de l'art des m{\'{e}}thodes de segmentation
survey},
author = {Eckley, Idris A. and Fearnhead, Paul and Killick, Rebecca},
booktitle = {Bayesian Time Series Models},
doi = {10.1017/CBO9780511984679.011},
editor = {Barber, David and Cemgil, A Taylan and Chiappa, Silvia},
file = {:home/charles/Documents/Mendeley Desktop/Unknown - Unknown - Analysis of changepoint models.pdf:pdf},
isbn = {9780511984679},
pages = {205--224},
publisher = {Cambridge University Press},
title = {{Analysis of changepoint models}},
url = {http://dx.doi.org/10.1017/CBO9780511984679.011},
year = {2011}
}
@article{Ross2012,
annote = {M{\'{e}}thode control chart (on garde en m{\'{e}}moire tout le signal et on fait une single breakpoint detection).
homogeneity testing: kolmogorov, cramer von mises},
author = {Ross, Gordon J. and Adams, Niall M.},
file = {:home/charles/Documents/Mendeley Desktop/Unknown - Unknown - Ross - Two Nonparametric Control Charts for Detecting Arbitrary Distribution Changes.pdf:pdf},
journal = {Journal of Quality Technology},
number = {2},
pages = {102--117},
title = {{Two Nonparametric Control Charts for Detecting Arbitrary Distribution Changes}},
volume = {44},
year = {2012}
}
@article{Levy-Leduc2009,
abstract = {We propose a novel and efficient method, that we shall call TopRank in the following paper, for detecting change-points in high-dimensional data. This issue is of growing concern to the network security community since network anomalies such as Denial of Service (DoS) attacks lead to changes in Internet traffic. Our method consists of a data reduction stage based on record filtering, followed by a nonparametric change-point detection test based on {\$}U{\$}-statistics. Using this approach, we can address massive data streams and perform anomaly detection and localization on the fly. We show how it applies to some real Internet traffic provided by France-T$\backslash$'el$\backslash$'ecom (a French Internet service provider) in the framework of the ANR-RNRT OSCAR project. This approach is very attractive since it benefits from a low computational load and is able to detect and localize several types of network anomalies. We also assess the performance of the TopRank algorithm using synthetic data and compare it with alternative approaches based on random aggregation.},
annote = {m{\'{e}}thode {\`{a}} fen{\^{e}}tre
two sample test sur chaque fen{\^{e}}tre.},
archivePrefix = {arXiv},
arxivId = {0908.2310},
author = {L{\'{e}}vy-Leduc, C{\'{e}}line and Roueff, Fran{\c{c}}ois},
doi = {10.1214/08-AOAS232},
eprint = {0908.2310},
file = {:home/charles/Documents/Mendeley Desktop/L{\'{e}}vy-Leduc, Roueff - 2009 - Detection and localization of change-points in high-dimensional network traffic data.pdf:pdf},
isbn = {1122201192},
journal = {The Annals of Applied Statistics},
keywords = {Change-point detection,High-dimensional data,Network anomaly detection,Rank tests},
number = {2},
pages = {637--662},
title = {{Detection and localization of change-points in high-dimensional network traffic data}},
volume = {3},
year = {2009}
}
@inproceedings{Mellor2013,
address = {Scottsdale, AZ, USA},
author = {Mellor, Joseph and Shapiro, Jonathan},
booktitle = {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics (AISTATS)},
file = {:home/charles/Documents/Mendeley Desktop/Mellor, Shapiro - 2013 - Thompson Sampling in Switching Environments with Bayesian Online Change Point Detection.pdf:pdf},
pages = {442--450},
title = {{Thompson Sampling in Switching Environments with Bayesian Online Change Point Detection}},
year = {2013}
}
@inproceedings{Lefakis2014,
address = {Beijing, China},
annote = {Dynamic programming et boosting pour avoir un classifieur par r{\'{e}}gime.},
author = {Lefakis, Leonidas and Fleuret, Francois},
booktitle = {Proceedings of The 31st International Conference on Machine Learning},
file = {:home/charles/Documents/Mendeley Desktop/Lefakis, Fleuret - 2014 - Dynamic Programming Boosting for Discriminative Macro-Action Discovery.pdf:pdf},
pages = {1548--1556},
title = {{Dynamic Programming Boosting for Discriminative Macro-Action Discovery}},
year = {2014}
}
@inproceedings{Lajugie2014,
address = {Beijing, China},
author = {Lajugie, R. and Bach, F. and Arlot, S.},
booktitle = {Proceedings of The 31st International Conference on Machine Learning (ICML)},
file = {:home/charles/Documents/Mendeley Desktop/Lajugie, Bach, Arlot - 2014 - Large-Margin Metric Learning for Constrained Partitioning Problems.pdf:pdf},
pages = {297--395},
title = {{Large-Margin Metric Learning for Constrained Partitioning Problems}},
year = {2014}
}
@article{Rissanen1983,
annote = {Introduction de la p{\'{e}}nalit{\'{e}} Minimum Description Length (MDL) en toute g{\'{e}}n{\'{e}}ralit{\'{e}}.
Elle est mieux d{\'{e}}taill{\'{e}}e dans la th{\`{e}}se de Stanislas Boutoille.},
author = {Rissanen, Jorma},
file = {:home/charles/Documents/Mendeley Desktop/Rissanen - 1983 - A universal prior for integers and estimation by minimum description length.pdf:pdf},
journal = {The Annals of Statistics},
number = {2},
pages = {416--431},
title = {{A universal prior for integers and estimation by minimum description length}},
volume = {11},
year = {1983}
}
@article{Schwarz1978,
annote = {Introduction du crit{\`{e}}re BIC (en tout g{\'{e}}n{\'{e}}ralit{\'{e}}).},
author = {Schwarz, Gideon},
file = {:home/charles/Documents/Mendeley Desktop/Schwarz - 1978 - Estimating the dimension of a model.pdf:pdf},
journal = {The Annals of Statistics},
number = {2},
pages = {461--464},
title = {{Estimating the dimension of a model}},
volume = {6},
year = {1978}
}
@article{Killick2012a,
annote = {binary segmentation {\textless} exact segmentation
oceanographic data},
author = {Killick, R. and Fearnhead, P. and Eckley, I.},
file = {:home/charles/Documents/Mendeley Desktop/Killick, Fearnhead, Eckley - 2011 - Optimal detection of changepoints with a linear computational cost.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {500},
pages = {1590--1598},
title = {{Optimal detection of changepoints with a linear computational cost}},
volume = {107},
year = {2012}
}
@article{Lebarbier2005,
author = {Lebarbier, {\'{E}}.},
file = {:home/charles/Documents/Mendeley Desktop/Lebarbier - 2005 - Detecting multiple change-points in the mean of Gaussian process by model selection.pdf:pdf},
journal = {Signal Processing},
number = {4},
pages = {717--736},
title = {{Detecting multiple change-points in the mean of gaussian process by model selection}},
volume = {85},
year = {2005}
}
@article{Birge2007,
annote = {A propos des p{\'{e}}nalit{\'{e}}s pour changement de moyenne gaussienne. 
Pour l'{\'{e}}tat de l'art des p{\'{e}}nalit{\'{e}}s.},
author = {Birg{\'{e}}, Lucien and Massart, Pascal},
file = {:home/charles/Documents/Mendeley Desktop/Birg{\'{e}}, Massart - 2007 - Minimal penalties for Gaussian model selection.pdf:pdf},
journal = {Probability Theory and Related Fields},
number = {1},
pages = {33--73},
title = {{Minimal penalties for Gaussian model selection}},
volume = {138},
year = {2007}
}
@article{Birge2001,
annote = {A propos des p{\'{e}}nalit{\'{e}}s pour changement de moyenne gaussienne.

Pour l'{\'{e}}tat de l'art des p{\'{e}}nalit{\'{e}}s.},
author = {Birg{\'{e}}, Lucien and Massart, Pascal},
file = {:home/charles/Documents/Mendeley Desktop/Birg{\'{e}}, Massart - 2001 - Gaussian model selection.pdf:pdf},
journal = {Journal of the European Mathematical Society},
number = {3},
pages = {203--268},
title = {{Gaussian model selection}},
volume = {3},
year = {2001}
}
@article{Liu2013,
abstract = {The objective of change-point detection is to discover abrupt property changes lying behind time-series data. In this paper, we present a novel statistical change-point detection algorithm based on non-parametric divergence estimation between time-series samples from two retrospective segments. Our method uses the relative Pearson divergence as a divergence measure, and it is accurately and efficiently estimated by a method of direct density-ratio estimation. Through experiments on artificial and real-world datasets including human-activity sensing, speech, and Twitter messages, we demonstrate the usefulness of the proposed method. {\textcopyright} 2013 Elsevier Ltd.},
annote = {m{\'{e}}thode {\`{a}} fen{\^{e}}tres.
Plusieurs exemples de datasets r{\'{e}}els en fin d'article.},
archivePrefix = {arXiv},
arxivId = {1203.0453},
author = {Liu, Song and Yamada, Makoto and Collier, Nigel and Sugiyama, Masashi},
doi = {10.1016/j.neunet.2013.01.012},
eprint = {1203.0453},
file = {:home/charles/Documents/Mendeley Desktop/Liu et al. - 2013 - Change-point detection in time-series data by relative density-ratio estimation.pdf:pdf},
isbn = {9783642341656},
issn = {08936080},
journal = {Neural Networks},
keywords = {Change-point detection,Distribution comparison,Kernel methods,Relative density-ratio estimation,Time-series data},
pmid = {23500502},
title = {{Change-point detection in time-series data by relative density-ratio estimation}},
year = {2013}
}
@misc{Reeves2007,
abstract = {This review article enumerates, categorizes, and compares many of the methods that have been proposed to detect undocumented changepoints in climate data series. The methods examined include the standard normal homogeneity (SNH) test, Wilcoxon's nonparametric test, two-phase regression (TPR) procedures, inhomogeneity tests, information criteria procedures, and various variants thereof. All of these methods have been proposed in the climate literature to detect undocumented changepoints, but heretofore there has been little formal comparison of the techniques on either real or simulated climate series. This study seeks to unify the topic, showing clearly the fundamental differences among the assumptions made by each procedure and providing guidelines for which procedures work best in different situations. It is shown that the common trend TPR and Sawa's Bayes criteria procedures seem optimal for most climate time series, whereas the SNH procedure and its nonparametric variant are probably best when trend and periodic effects can be diminished by using homogeneous reference series. Two applications to annual mean tem- perature series are given. Directions for future research are discussed.},
annote = {Review de techniques de d{\'{e}}tection de ruptures.
Se limite {\`{a}} une seule rupture.
Que des mean shifts ou changement de tendances.
200 citations.},
author = {Reeves, Jaxk and Chen, Jien and Wang, Xiaolan L. and Lund, Robert and Lu, QiQi Q.},
booktitle = {Journal of Applied Meteorology and Climatology},
doi = {10.1175/JAM2493.1},
file = {:home/charles/Documents/Mendeley Desktop/Reeves et al. - 2007 - A review and comparison of changepoint detection techniques for climate data.pdf:pdf},
isbn = {1558-8424},
issn = {15588424},
title = {{A review and comparison of changepoint detection techniques for climate data}},
year = {2007}
}
@article{Hocking2013,
annote = {Apprentissages de p{\'{e}}nalit{\'{e}}s par CV et autres m{\'{e}}thodes simples.},
author = {Hocking, T. and Schleiermacher, G. and Janoueix-Lerosey, I. and Boeva, V. and Cappo, J. and Delattre, O. and Bach, F. and Vert, J.-P.},
file = {:home/charles/Documents/Mendeley Desktop/Hocking et al. - 2013 - Learning smoothing models of copy number profiles using breakpoint annotations.pdf:pdf},
journal = {BMC Bioinformatics},
number = {1},
pages = {164},
title = {{Learning smoothing models of copy number profiles using breakpoint annotations}},
volume = {14},
year = {2013}
}
@article{Michie1968,
abstract = {It would be useful if computers could learn from experience and thus automatically improve the efficiency of their own programs during execution. A simple but effective rote-learning facility can be provided within the framework of a suitable programming language.},
annote = {Article fondateur sur la memoization (ou simplement "memo").},
author = {Michie, Donald},
doi = {10.1038/218019a0},
file = {:home/charles/Documents/Mendeley Desktop/Michie - 1968 - Memo Functions and Machine Learning.pdf:pdf},
journal = {Nature},
number = {5136},
pages = {19--22},
title = {{"Memo" Functions and Machine Learning}},
volume = {218},
year = {1968}
}
@article{Kehagias2004,
abstract = {Motivated by Hubert's segmentation procedure we discuss the application of hidden Markov models (HMM) to the segmentation of hydrological and enviromental time series. We use a HMM algorithm which segments time series of several hundred terms in a few seconds and is computationally feasible for even longer time series. The segmentation algorithm computes the Maximum Likelihood segmentation by use of an expectation maximization iteration. We rigorously prove algorithm convergence and use numerical experiments, involving temperature and river discharge time series, to show that the algorithm usually converges to the globally optimal segmentation. The relation of the proposed algorithm to Hubert's segmentation procedure is also discussed.},
annote = {HMM pour faire de la d{\'{e}}tection de ruptures.

Dynamic programming pour la d{\'{e}}tection de ruptures dans les exp{\'{e}}riences.

Fonction de cout: erreur quadratique constante.},
archivePrefix = {arXiv},
arxivId = {cs/0206039},
author = {Kehagias, Ath},
doi = {10.1007/s00477-003-0145-5},
eprint = {0206039},
file = {:home/charles/Documents/Mendeley Desktop/Kehagias - 2004 - Hidden Markov model segmentation of hydrological and enviromental time series.pdf:pdf},
journal = {Stochastic Environmental Research and Risk Assessment (SERRA)},
number = {2},
pages = {117--130},
primaryClass = {cs},
title = {{Hidden Markov model segmentation of hydrological and enviromental time series}},
volume = {18},
year = {2004}
}
@article{Fragkou2004,
abstract = {In this paper we introduce a dynamic programming algorithm which performs linear text segmentation by global minimization of a segmentation cost function which incorporates two factors: (a) within-segment word similarity and (b) prior information about segment length. We evaluate segmentation accuracy of the algorithm by precision, recall and Beeferman's segmentation metric. On a segmentation task which involves Choi's text collection, the algorithm achieves the best segmentation accuracy so far reported in the literature. The algorithm also achieves high accuracy on a second task which involves previously unused texts.},
annote = {{\'{e}}tat de l'art dynamic programming mais pour de la segmentation de textes.},
author = {Fragkou, P. and Petridis, V. and Kehagias, Ath},
doi = {10.1023/B:JIIS.0000039534.65423.00},
file = {:home/charles/Documents/Mendeley Desktop/Fragkou, Petridis, Kehagias - 2004 - A dynamic programming algorithm for linear text segmentation.pdf:pdf},
journal = {Journal of Intelligent Information Systems},
keywords = {Document retrieval,Information retrieval,Machine learning,Text segmentation,dynamic programming},
mendeley-tags = {dynamic programming},
number = {2},
pages = {179--197},
title = {{A dynamic programming algorithm for linear text segmentation}},
volume = {23},
year = {2004}
}
@book{Kay1998,
annote = {A citer pour l'utilisation du dynamic programming pour la d{\'{e}}tection de ruptures.},
author = {Kay, S.},
edition = {1},
editor = {Hall, Prentice},
isbn = {978-0135041352},
keywords = {dynamic programming},
mendeley-tags = {dynamic programming},
publisher = {Prentice Hall},
title = {{Fundamentals of statistical signal processing: detection theory}},
year = {1998}
}
@article{Jackson2005,
abstract = {Many signal processing problems can be solved by maximizing the fitness of a segmented model over all possible partitions of the data interval. This letter describes a simple but powerful algorithm that searches the exponentially large space of partitions of N data points in time O(N2). The algorithm is guaranteed to find the exact global optimum, automatically determines the model order (the number of segments), has a convenient real-time mode, can be extended to higher dimensional data spaces, and solves a surprising variety of problems in signal detection and characterization, density estimation, cluster analysis, and classification.},
annote = {Explique le dynamic programming dans le cadre de la d{\'{e}}tection de ruptures.
Ils citent une grande partie des articles qui utilisent le DP.},
archivePrefix = {arXiv},
arxivId = {math/0309285},
author = {Jackson, B. and Scargle, J. D. and Barnes, D. and Arabhi, S. and Alt, A. and Gioumousis, P. and Gwin, E. and Sangtrakulcharoen, P. and Tan, L. and Tsai, Tun Tao},
doi = {10.1109/LSP.2001.838216},
eprint = {0309285},
file = {:home/charles/Documents/Mendeley Desktop/Jackson et al. - 2005 - An algorithm for optimal partitioning of data on an interval.pdf:pdf},
journal = {IEEE Signal Processing Letters},
keywords = {Bayesian modeling,Cluster analysis,Density estimation,Histograms,Optimization,Signal detection},
number = {2},
pages = {105--108},
primaryClass = {math},
title = {{An algorithm for optimal partitioning of data on an interval}},
volume = {12},
year = {2005}
}
@article{Killick2012b,
author = {Killick, R. and Eckley, P.},
file = {:home/charles/Documents/Mendeley Desktop/Killick, Eckley - 2012 - Supporting Material Optimal detection of changepoints with a linear computational cost.pdf:pdf},
title = {{Supporting Material: Optimal detection of changepoints with a linear computational cost}},
year = {2012}
}
@article{Rigaill,
abstract = {A common computational problem in multiple change-point models is to recover the segmentations with 1 to K max change-points of minimal cost with respect to some loss function. Here we present an algorithm to prune the set of candidate change-points which is based on a functional representation of the cost of segmentations. We study the worst case complexity of the algorithm when there is a unidimensional parameter per segment and demonstrate that it is at worst equivalent to the complexity of the segment neighbourhood algorithm: O(K max n 2). For a particular loss function we demonstrate that pruning is on average efficient even if there are no change-points in the signal. Finally, we empirically study the performance of the algorithm in the case of the quadratic loss and show that it is faster than the segment neighbourhood algorithm.},
annote = {Le "pruning" peut {\^{e}}tre cod{\'{e}} seulement pour les fonctions de co{\^{u}}t avec un seul param{\`{e}}tre (la moyenne par exemple) et si le co{\^{u}}t est unimodale quand ce param{\`{e}}tre varie.
Applied on DNA sequence data
Reformulation en somme de couts},
author = {Rigaill, G.},
file = {:home/charles/Documents/Mendeley Desktop/Rigaill - Unknown - A pruned dynamic programming algorithm to recover the best segmentations with 1 to K max change-points.pdf:pdf},
journal = {Journal de la Soci{\'{e}}t{\'{e}} Fran{\c{c}}aise de Statistique},
keywords = {dynamic programming,functional cost,multiple-change-point detection,segment neigh-bourhood},
number = {4},
pages = {180--205},
title = {{A pruned dynamic programming algorithm to recover the best segmentations with 1 to K{\_}max change-points.}},
volume = {156},
year = {2015}
}
@inproceedings{Rigailla,
address = {Atlanta, USA},
author = {Hocking, T. and Rigaill, G and Vert, J.-P. and Bach, F.},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
file = {:home/charles/Documents/Mendeley Desktop/Hocking et al. - 2013 - Learning Sparse Penalties for Change-Point Detection using Max Margin Interval Regression.pdf:pdf},
pages = {172--180},
title = {{Learning Sparse Penalties for Change-Point Detection using Max Margin Interval Regression}},
year = {2013}
}
@phdthesis{Boutoille2007,
author = {Boutoille, Stanislas},
file = {:home/charles/Documents/Mendeley Desktop/Boutoille - 2007 - Syst{\`{e}}mes de fusion pour la segmentation hors-ligne de signaux GPS multi-porteuses.pdf:pdf},
school = {Universit{\'{e}} du Littoral C{\^{o}}te d'Opale},
title = {{Syst{\`{e}}mes de fusion pour la segmentation hors-ligne de signaux GPS multi-porteuses}},
url = {https://tel.archives-ouvertes.fr/tel-00139226v3},
year = {2007}
}
@article{Arias-Castro,
abstract = {The scan statistic is by far the most popular method for anomaly detection, being popular in syndromic surveillance, signal and image processing, and target detection based on sensor networks, among other applications. The use of the scan statistics in such settings yields an hypothesis testing procedure, where the null hypothesis corresponds to the absence of anomalous behavior. If the null distribution is known, then calibration of a scan-based test is relatively easy, as it can be done by Monte-Carlo simulation. When the null distribution is unknown, it is less straightforward. We investigate two procedures. The first one is a calibration by permutation and the other is a rank-based scan test, which is distribution-free and less sensitive to outliers. Furthermore, the rank-scan test requires only a one-time calibration for a given data size making it computationally much more appealing. In both cases, we quantify the performance loss with respect to an oracle scan test that knows the null distribution. We show that using one of these calibration procedures results in only a very small loss of power in the context of a natural exponential family . This includes the classical normal location model, popular in signal processing, and the Poisson model, popular in syndromic surveillance. We perform numerical experiments on simulated data further supporting our theory and also on a real dataset from genomics.},
author = {Arias-Castro, Ery and Castro, Rui M and T{\'{a}}nczos, Ervin and Wang, Meng},
file = {:home/charles/Documents/Mendeley Desktop/Arias-Castro et al. - Unknown - Distribution-Free Detection of Structured Anomalies Permutation and Rank-Based Scans.pdf:pdf},
title = {{Distribution-Free Detection of Structured Anomalies: Permutation and Rank-Based Scans}}
}
@article{Bai1998,
abstract = {This paper develops methods for constructing asymptotically valid confidence intervals for the date of a single break in multivariate time series, including I(0), I(1), and deterministically trending regressors. Although the width of the asymptotic confidence interval does not decrease as the sample size increases, it is inversely related to the number of series which have a common break date, so there are substantial gains to multivariate inference about break dates. These methods are applied to two empirical examples: the mean growth rate of output in three European countries, and the mean growth rate of U.S. consumption, investment, and output.},
author = {Bai, J. and Lumsdaine, R. L. and Stock, J. H.},
doi = {10.1111/1467-937X.00051},
file = {:home/charles/Documents/Mendeley Desktop/Bai, Lumsdaine, Stock - 1998 - Testing For and Dating Common Breaks in Multivariate Time Series.pdf:pdf},
issn = {0034-6527, 1467-937X},
journal = {The Review of Economic Studies},
number = {3},
pages = {395--432},
title = {{Testing For and Dating Common Breaks in Multivariate Time Series}},
url = {http://restud.oxfordjournals.org/content/65/3/395{\%}5Cnhttp://restud.oxfordjournals.org/content/65/3/395.short},
volume = {65},
year = {1998}
}
@article{Verbesselt2010,
author = {Verbesselt, Jan and Hyndman, Rob and Newnham, Glenn and Culvenor, Darius},
file = {:home/charles/Documents/Mendeley Desktop/Verbesselt et al. - 2010 - Detecting trend and seasonal changes in satellite images time series.pdf:pdf},
isbn = {6139545226},
journal = {Remote Sensing of Environment},
number = {114},
pages = {106--115},
title = {{Detecting trend and seasonal changes in satellite images time series}},
year = {2010}
}
@article{Bai2003,
abstract = {Summary. Bai and Perron (1998) considered theoretical issues related to the limiting distribution of estimators and test statistics in the linear model with multiple structural changes. The asymptotic distributions of the tests depend on a trimming parameter $\epsilon$ and critical values were tabulated for $\epsilon$= 0.05. As discussed in Bai and Perron (2000), larger values of $\epsilon$ are needed to achieve tests with correct size in finite samples, when allowing for heterogeneity across segments or serial correlation in the errors. The aim of this paper is to supplement the set of critical values available with other values of $\epsilon$ to enable proper empirical applications. We provide response surface regressions valid for a wide range of parameters.},
annote = {NULL},
author = {Bai, J. and Perron, P.},
file = {:home/charles/Documents/Mendeley Desktop/Bai, Perron - 2003 - Critical values for multiple structural change tests.pdf:pdf},
journal = {Econometrics Journal},
number = {1},
pages = {72--78},
title = {{Critical values for multiple structural change tests}},
volume = {6},
year = {2003}
}
@article{Perron2006,
abstract = {This chapter is concerned with methodological issues related to estimation, testing and computation in the context of structural changes in the linear models. A central theme of the review is the interplay between structural change and unit root and on methods to distinguish between the two. The topics covered are: methods related to estimation and inference about break dates for single equations with or without restrictions, with extensions to multi-equations systems where allowance is also made for changes in the variability of the shocks; tests for structural changes including tests for a single or multiple changes and tests valid with unit root or trending regressors, and tests for changes in the trend function of a series that can be integrated or trendstationary; testing for a unit root versus trend-stationarity in the presence of structural changes in the trend function; testing for cointegration in the presence of structural changes; and issues related to long memory and level shifts. Our focus is on the conceptual issues about the frameworks adopted and the assumptions imposed as they relate to potential applicability. We also highlight the potential problems that can occur with methods that are commonly used and recent work that has been done to overcome them.},
author = {Perron, P.},
doi = {10.1016/j.gfj.2006.04.004},
file = {:home/charles/Documents/Mendeley Desktop/Perron - 2006 - Dealing with structural breaks.pdf:pdf},
issn = {10440283},
journal = {Palgrave handbook of econometrics},
pages = {278--352},
title = {{Dealing with structural breaks}},
url = {http://people.bu.edu/perron/papers/dealing.pdf},
volume = {1},
year = {2006}
}
@article{Bai2004,
author = {Bai, J. and Perron, P.},
doi = {10.1017/CBO9781139164863.010},
file = {:home/charles/Documents/Mendeley Desktop/Bai, Perron - 2004 - Multiple structural change models a simulation analysis.pdf:pdf},
isbn = {9781139164863},
journal = {Working Papers},
pages = {1--29},
title = {{Multiple structural change models: a simulation analysis}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=mXitlEaAy8AC{\&}oi=fnd{\&}pg=PA212{\&}dq=Multiple+structural+Change+models:+a+simulation+analysis{\&}ots=dBUofO8XeD{\&}sig=Y11X6pJHk22mdkAsWXR-qiwDCmU},
year = {2004}
}
@article{Haber2014,
annote = {M{\'{e}}thodes bay{\'{e}}siennes qui utilisent le "run-length"

M{\'{e}}thode en ligne.
Adaptation d'une m{\'{e}}thode tir{\'{e}}e de "Bayesian online changepoint d{\'{e}}tection", mais en plus rapide (lin{\'{e}}aire plut{\^{o}}t que quadratique): au lieu de prendre en compte tout le signal, on en oublie le d{\'{e}}but au fur et {\`{a}} mesure qu'on avance.},
author = {Haber, D and Thomik, Aac and Faisal, Aa},
doi = {10.1109/BSN.2014.34},
file = {:home/charles/Documents/Mendeley Desktop/Haber, Thomik, Faisal - 2014 - Unsupervised time series segmentation for high-dimensional body sensor network data streams.pdf:pdf},
isbn = {9781479949595},
journal = {Body Sensor Networks},
number = {1},
pages = {121--126},
title = {{Unsupervised time series segmentation for high-dimensional body sensor network data streams}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6855628},
year = {2014}
}
@article{Qu2007,
abstract = {This paper considers issues related to estimation, inference, and computation with multiple structural changes that occur at unknown dates in a system of equations. Changes can occur in the regression coefficients and/or the covariance matrix of the errors. We also allow arbitrary restrictions on these parameters, which permits the analysis of partial structural change models, common breaks that occur in all equations, breaks that occur in a subset of equations, and so forth. The method of estimation is quasi-maximum likelihood based on Normal errors. The limiting distributions are obtained under more general assumptions than previous studies. For testing, we propose likelihood ratio type statistics to test the null hypothesis of no structural change and to select the number of changes. Structural change tests with restrictions on the parameters can be constructed to achieve higher power when prior information is present. For computation, an algorithm for an efficient procedure is proposed to construct the estimates and test statistics. We also introduce a novel locally ordered breaks model, which allows the breaks in different equations to be related yet not occurring at the same dates.},
annote = {marche pour les arma
estimation par quasi likelihood.},
author = {Qu, Z. and Perron, P.},
doi = {10.1111/j.1468-0262.2006.00754.x},
file = {:home/charles/Documents/Mendeley Desktop/Qu, Perron - 2007 - Estimating and testing structural changes in multivariate regressions.pdf:pdf},
isbn = {1468-0262},
issn = {00129682},
journal = {Econometrica},
keywords = {Break dates,Change-point,Hypothesis testing,Model selection,Segmented regressions,System of regressions},
number = {2},
pages = {459--502},
title = {{Estimating and testing structural changes in multivariate regressions}},
volume = {75},
year = {2007}
}
@article{Bai1998a,
annote = {Donne une vitesse de convergence sur les temps de ruptures calcul{\'{e}}s par optmisation globale.
Mod{\`{e}}le lin{\'{e}}aire par morceaux. 
Preuve de la consistance des estimateurs des temps de rupture.},
author = {Bai, J. and Perron, P.},
file = {:home/charles/Documents/Mendeley Desktop/Bai, Perron - 1998 - Estimating and Testing Linear Models with Multiple Structural Changes.pdf:pdf},
journal = {Econometrica},
number = {1},
pages = {47--78},
title = {{Estimating and Testing Linear Models with Multiple Structural Changes}},
volume = {66},
year = {1998}
}
@misc{Benjamini1995,
abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
archivePrefix = {arXiv},
arxivId = {0035-9246/95/57289},
author = {Benjamini, Yoav and Hochberg, Yosef},
booktitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
doi = {10.2307/2346101},
eprint = {95/57289},
file = {:home/charles/Documents/Mendeley Desktop/Benjamini, Hochberg - 1995 - Controlling the False Discovery Rate A Practical and Powerful Approach to Multiple Testing.pdf:pdf},
isbn = {1023072346},
issn = {00359246},
number = {1},
pages = {289 -- 300},
pmid = {2346101},
primaryClass = {0035-9246},
title = {{Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing}},
url = {http://www.jstor.org/stable/2346101},
volume = {57},
year = {1995}
}
@article{Benjamini2010,
abstract = {I describe the background for the paper ‘Controlling the false discovery rate: a new and powerful approach tomultiple comparisons'by Benjamini and Hochberg thatwas published in the Journal of the Royal Statistical Society, Series B, in 1995. I review the progress since made on the false discovery rate, as well as the major conceptual developments that followed.},
author = {Benjamini, Y},
doi = {10.1111/j.1467-9868.2010.00746.x},
file = {:home/charles/Documents/Mendeley Desktop/Benjamini - 2010 - Discovering the false discovery rate.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society: Series B},
keywords = {false coverage rate,multiple comparisons,testimation},
number = {4},
pages = {405--416},
title = {{Discovering the false discovery rate}},
url = {http://doi.wiley.com/10.1111/j.1467-9868.2010.00746.x},
volume = {72},
year = {2010}
}
@article{Cox1955,
author = {Cox, David Roxbee and Stuart, Alan},
journal = {Biometrika},
pages = {80----95},
title = {{Some quick sign tests for trend in location and dispersion}},
year = {1955}
}
@article{Benjamini2001,
author = {Benjamini, Yoav and Yekutieli, Daniel},
file = {:home/charles/Documents/Mendeley Desktop/Benjamini, Yekutieli - 2001 - The control of the false discovery rate in multiple testing under depencency.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {and phrases,equality,fdr,hochberg,multiple comparisons procedures,s,simes},
number = {4},
pages = {1165--1188},
title = {{The control of the false discovery rate in multiple testing under depencency}},
volume = {29},
year = {2001}
}
@article{Kohlmorgen2000a,
abstract = {Presents a method for the analysis of time series from drifting or switching dynamics. In an extension to existing approaches that identify switches or drifts between stationary dynamical modes, the method allows one to analyze even continuously varying dynamics and can identify mixtures of more than two dynamical modes. The architecture is based on a mixture of self-organizing Nadaraya-Watson kernel estimators. The mixture model is trained by barrier optimization, a technique for constrained optimization problems. We apply the proposed method to artificially generated data and EEG recordings from the wake/sleep transition},
author = {Kohlmorgen, J. and Lemm, S. and Ratsch, G. and Muller, K.-R.},
doi = {10.1109/NNSP.2000.889365},
file = {:home/charles/Documents/Mendeley Desktop/Kohlmorgen et al. - 2000 - Analysis of nonstationary time series by mixtures of self-organizing predictors.pdf:pdf},
isbn = {0-7803-6278-0},
issn = {1089-3555},
journal = {Neural Networks for Signal Processing X. Proceedings of the 2000 IEEE Signal Processing Society Workshop (Cat. No.00TH8501)},
title = {{Analysis of nonstationary time series by mixtures of self-organizing predictors}},
volume = {1},
year = {2000}
}
@article{Chang2004,
abstract = {We present a framework for the unsupervised segmentation of switching dynamics using support vector machines. Following the architecture by Pawelzik et al., where annealed competing neural networks were used to segment a nonstationary time series, in this paper, we exploit the use of support vector machines, a well-known learning technique. First, a new formulation of support vector regression is proposed. Second, an expectation-maximization step is suggested to adaptively adjust the annealing parameter. Results indicate that the proposed approach is promising. Index},
author = {Chang, M. and Lin, C. and Weng, R. C.},
file = {:home/charles/Documents/Mendeley Desktop/Chang, Lin, Weng - 2004 - Analysis of switching dynamics with competing support vector machines.pdf:pdf},
journal = {IEEE Transactions on Neural Networks},
number = {3},
pages = {720--727},
title = {{Analysis of switching dynamics with competing support vector machines}},
volume = {15},
year = {2004}
}
@article{Verdes2006,
abstract = {We propose a general overembedding method for modeling and prediction of nonstationary systems. It basically enlarges the standard time-delay-embedding space by inclusion of the (unknown) slow driving signal, which is estimated simultaneously with the intrinsic stationary dynamics. Our method can be implemented with any modeling tool. Using, in particular, artificial neural networks, its application to both synthetic and real-world time series shows that it is highly efficient, leading to much more accurate results and longer prediction horizons than other existing overembedding method},
author = {Verdes, F. P. and Granitto, P. M. and Ceccatto, H. A.},
journal = {Physical Review Letters},
number = {11},
pages = {118701},
title = {{Overembedding Method for Modeling Nonstationary Systems}},
volume = {96},
year = {2006}
}
@article{Kohlmorgen2000,
abstract = {We present a novel framework for the analysis of time series from dynamical systems that alternate between different operating modes. The method simultaneously segments and identifies the dynamical modes by using predictive models. In extension to previous approaches, it allows an identification of smooth transition between successive modes. The method can be used for analysis, diagnosis, prediction, and control. In an application to EEG and respiratory data recorded from humans during afternoon naps, the obtained segmentations of the data agree with the sleep stage segmentation of a medical expert to a large extent. However, in contrast to the manual segmentation, our method does not require a priori knowledge about physiology. Moreover, it has a high temporal resolution and reveals previously unclassified details of the transitions. In particular, a parameter is found that is potentially helpful for vigilance monitoring. We expect that the method will generally be useful for the analysis of nonstationary dynamical systems, which are abundant in medicine, chemistry, biology and engineering.},
annote = {{\c{c}}a n'a pas l'air de super bien marcher.},
author = {Kohlmorgen, J. and M{\"{u}}ller, K. R. and Rittweger, J. and Pawelzik, K.},
doi = {10.1007/s004220000144},
file = {:home/charles/Documents/Mendeley Desktop/Kohlmorgen et al. - 2000 - Identification of nonstationary dynamics in physiological recordings.pdf:pdf},
isbn = {0340-1200 (Print)},
issn = {0340-1200},
journal = {Biological cybernetics},
number = {1},
pages = {73--84},
pmid = {10933239},
title = {{Identification of nonstationary dynamics in physiological recordings.}},
volume = {83},
year = {2000}
}
@article{Nason2013,
abstract = {Many time series are not second order stationary and it is not appropriate to analyse them by using methods designed for stationary series. The paper introduces a new test for second-order stationarity that detects kinds of departures from stationarity that are different from those based on Fourier methods. The new test is also computationally fast, designed to work with Gaussian and a wide range of non-Gaussian time series, and can locate non-stationarities in time and scale. The test is demonstrated on earthquake, explosion, infant electrocardiogram and simulated time series showing varying degrees of stationarity. The second main contribution develops approximate confidence intervals for time varying autocovariances for locally stationary series as the usual bands computed for stationary series are not appropriate. Our new bands enable practitioners to assess time varying autocovariances statistically and are exhibited on localized autocovariances of explosion and simulated time series.},
author = {Nason, G.},
doi = {10.1111/rssb.12015},
file = {:home/charles/Documents/Mendeley Desktop/Nason - 2013 - A test for second-order stationarity and approximate confidence intervals for localized autocovariances for locally stati.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Confidence intervals,Local autocovariance,Locally stationary,Stationarity test},
number = {5},
pages = {879--904},
title = {{A test for second-order stationarity and approximate confidence intervals for localized autocovariances for locally stationary time series}},
volume = {75},
year = {2013}
}
@article{HashemPesaran2006,
abstract = {This paper provides a novel approach to forecasting time series subject to discrete structural breaks. We propose a Bayesian estimation and prediction procedure that allows for the possibility of new breaks over the forecast horizon, taking account of the size and duration of past breaks (if any) by means of a hierarchical hidden Markov chain model. Predictions are formed by integrating over the hyper parameters from the meta distributions that characterise the stochastic break point process. In an application to US Treasury bill rates, we find that the method leads to better out-of-sample forecasts than alternative methods that ignore breaks, particularly at long horizons.},
author = {{Hashem Pesaran}, M. and Pettenuzzo, Davide and Timmermann, Allan},
doi = {10.1111/j.1467-937X.2006.00408.x},
file = {:home/charles/Documents/Mendeley Desktop/Hashem Pesaran, Pettenuzzo, Timmermann - 2006 - Forecasting time series subject to multiple structural breaks.pdf:pdf},
issn = {00346527},
journal = {Review of Economic Studies},
keywords = {bayesian model averag-,forecasting,hierarchical hidden markov chain,structural breaks},
number = {4},
pages = {1057--1084},
title = {{Forecasting time series subject to multiple structural breaks}},
volume = {73},
year = {2006}
}
@article{Zhou2015,
abstract = {This paper considers the problem of testing the equality of two unspecified distributions. The classical omnibus tests such as the Kolmogorov-Smirnov and Cram$\backslash$`er-von Mises are known to suffer from low power against essentially all but location-scale alternatives. We propose a new two-sample test that modifies the Neyman's smooth test and extend it to the multivariate case based on the idea of projection pursue. The asymptotic null property of the test and its power against local alternatives are studied. The multiplier bootstrap method is employed to compute the critical value of the multivariate test. We establish validity of the bootstrap approximation in the case where the dimension is allowed to grow with the sample size. Numerical studies show that the new testing procedures perform well even for small sample sizes and are powerful in detecting local features or high-frequency components},
archivePrefix = {arXiv},
arxivId = {1509.03459},
author = {Zhou, Wen-xin and Zheng, Chao and Zhang, Zhen},
eprint = {1509.03459},
file = {:home/charles/Documents/Mendeley Desktop/Zhou, Zheng, Zhang - 2015 - Two-Sample Smooth Tests for the Equality of Distributions.pdf:pdf},
keywords = {alternations,goodness-of-fit,high-frequency,multiplier bootstrap,neyman,s smooth test,two-sample problem},
title = {{Two-Sample Smooth Tests for the Equality of Distributions}},
url = {http://arxiv.org/abs/1509.03459},
year = {2015}
}
@article{Geweke2011,
abstract = {This paper develops a new Bayesian approach to structural break modeling. The focuses of the approach are the modeling of in-sample structural breaks and forecasting time series allowing out-of-sample breaks. The model has several desirable features. First, the number of regimes is not fixed but is treated as a random variable. Second, the model adopts a hierarchical prior for regime coefficients, which allows for the coefficients of one regime to contain information about coefficients of other regimes. Third, the regime coefficients can be integrated analytically in the posterior density; as a consequence the posterior simulator is fast and reliable. An application to US real GDP quarterly growth rates links groups of regimes to specific historical periods and provides forecasts of future growth rates. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
annote = {s{\'{e}}ries iid 
m{\'{e}}thodes bayesiennes.},
author = {Geweke, John and Jiang, Yu},
doi = {10.1016/j.jeconom.2011.03.005},
file = {:home/charles/Documents/Mendeley Desktop/Geweke, Jiang - 2011 - Inference and prediction in a multiple-structural-break model.pdf:pdf},
isbn = {03044076},
issn = {03044076},
journal = {Journal of Econometrics},
number = {2},
pages = {172--185},
pmid = {1249909},
publisher = {Elsevier B.V.},
title = {{Inference and prediction in a multiple-structural-break model}},
url = {http://dx.doi.org/10.1016/j.jeconom.2011.03.005},
volume = {163},
year = {2011}
}
@article{Maheu2008,
abstract = {We provide a general methodology for forecasting in the presence of structural breaks induced by unpredictable changes to model parameters. Bayesian methods of learning and model comparison are used to derive a predictive density that takes into account the possibility that a break will occur before the next observation. Estimates for the posterior distribution of the most recent break are generated as a by-product of our procedure. We discuss the importance of using priors that accurately reflect the econometrician's opinions as to what constitutes a plausible forecast. Several applications to macroeconomic time-series data demonstrate the usefulness of our procedure. Copyright {\textcopyright} 2008 John Wiley {\&} Sons, Ltd.},
author = {Maheu, John M. and Gordon, Stephen},
doi = {10.1002/jae.1018},
file = {:home/charles/Documents/Mendeley Desktop/Maheu, Gordon - 2008 - Learning, forecasting and structural breaks.pdf:pdf},
issn = {08837252},
journal = {Journal of Applied Econometrics},
keywords = {bayesian model averaging,markov chain monte carlo,phillip,real gdp growth,s},
number = {5},
pages = {553--583},
title = {{Learning, forecasting and structural breaks}},
volume = {23},
year = {2008}
}
@article{Chib1998,
annote = {M{\'{e}}thode bayesienne.
Etats latents sous forme de chaine de Markov.},
author = {Chib, S.},
file = {:home/charles/Documents/Mendeley Desktop/Chib - 1998 - Estimation and comparison of multiple change-point models.pdf:pdf},
journal = {Journal of Econometrics},
number = {2},
pages = {221--241},
title = {{Estimation and comparison of multiple change-point models}},
volume = {86},
year = {1998}
}
@techreport{Adams2007,
abstract = {Changepoints are abrupt variations in the generative parameters of a data sequence. Online detection of changepoints is useful in modelling and prediction of time series in application areas such as finance, biometrics, and robotics. While frequentist methods have yielded online filtering and prediction techniques, most Bayesian papers have focused on the retrospective segmentation problem. Here we examine the case where the model parameters before and after the changepoint are independent and we derive an online algorithm for exact inference of the most recent changepoint. We compute the probability distribution of the length of the current ``run,'' or time since the last changepoint, using a simple message-passing algorithm. Our implementation is highly modular so that the algorithm may be applied to a variety of types of data. We illustrate this modularity by demonstrating the algorithm on three different real-world data sets.},
annote = {article fondateur de la technique du run length.

Utilise les donn{\'{e}}es well log (well drilling)

artcile arxiv},
archivePrefix = {arXiv},
arxivId = {0710.3742},
author = {{Prescott Adams}, R. and MacKay, D. J. C.},
booktitle = {ArXiv e-prints},
doi = {arXiv:0710.3742v1},
eprint = {0710.3742},
file = {:home/charles/Documents/Mendeley Desktop/Adams, MacKay - 2007 - Bayesian Online Changepoint Detection.pdf:pdf},
title = {{Bayesian Online Changepoint Detection}},
url = {http://arxiv.org/abs/0710.3742},
year = {2007}
}
@article{Identification2015,
author = {Stephens, D. A.},
file = {:home/charles/Documents/Mendeley Desktop/Stephens - 1994 - Bayesian Retrospective Multiple-Changepoint Identification.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
keywords = {discrete and continuous changepoint,gibbs sampler,models,multiple changepoint},
number = {1},
pages = {159--178},
title = {{Bayesian Retrospective Multiple-Changepoint Identification}},
volume = {43},
year = {1994}
}
@article{Giordani2005,
annote = {m{\'{e}}thodes bay{\'{e}}siennes.
mod{\`{e}}le lin{\'{e}}aire par morceaux.},
author = {Giordani, Paolo and Kohn, Robert},
file = {:home/charles/Documents/Mendeley Desktop/Giordani, Kohn - 2005 - E ffi cient Bayesian Inference for Multiple Change-Point and Mixture Innovation Models ∗.pdf:pdf},
keywords = {adaptive metropolis-,change-point,discrete latent variables,mixtures,parameter instability,state-space,structural breaks},
pages = {1--28},
title = {{E ffi cient Bayesian Inference for Multiple Change-Point and Mixture Innovation Models ∗}},
year = {2005}
}
@article{Ko2015,
abstract = {This paper proposes a new Bayesian multiple change-point model which is based on the hidden Markov approach. The Dirichlet process hidden Markov model does not require the specification of the number of change-points a priori . Hence our model is robust to model specification in contrast to the fully parametric Bayesian model. We propose a general Markov chain Monte Carlo algorithm which only needs to sample the states around change-points. Simulations for a normal mean-shift model with known and unknown variance demonstrate advantages of our approach. Two applications, namely the co al mining disaster data and the real United States Gross Domestic Product growth, are provided. We detect a single change-point for both the disaster data and US GDP growth. All the change-point locations and posterior inferences of the two applications are in line with existing methods},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.01665v1},
author = {Ko, S. I. M. and Chong, T. T. L. and Ghosh, P.},
doi = {10.1214/14-BA910},
eprint = {arXiv:1505.01665v1},
file = {:home/charles/Documents/Mendeley Desktop/Ko, Chong, Ghosh - 2015 - Dirichlet Process Hidden Markov Multiple Change-point Model.pdf:pdf},
issn = {1936-0975},
journal = {Bayesian Analysis},
keywords = {Change-point,Dirichlet process,Hidden Markov mod,chain monte carlo,change-point,dirichlet process,hidden markov model,markov,nonparametric bayesian},
number = {2},
pages = {275--296},
title = {{Dirichlet Process Hidden Markov Multiple Change-point Model}},
url = {http://projecteuclid.org/euclid.ba/1422884975},
volume = {10},
year = {2015}
}
@book{Basseville1993,
annote = {{\'{e}}tat de l'art en param{\'{e}}trique.
processus stationnaires par morceaux.
D{\'{e}}teection d'une seule rupture.},
author = {Basseville, M. and Nikiforov, I.},
doi = {10.1016/0967-0661(94)90196-1},
file = {:home/charles/Documents/Mendeley Desktop/Basseville, Nikiforov - 1993 - Detection of Abrupt Changes Theory and Application.pdf:pdf},
isbn = {0-13-126780-9},
issn = {09670661},
publisher = {Prentice Hall Englewood Cliffs},
title = {{Detection of Abrupt Changes: Theory and Application}},
volume = {104},
year = {1993}
}
@unpublished{Dwork2015,
abstract = {A great deal of effort has been devoted to reducing the risk of spurious scientific discoveries, from the use of sophisticated validation techniques, to deep statistical methods for controlling the false discovery rate in multiple hypothesis testing. However, there is a fundamental discon- nect between the theoretical results and the practice of data analysis: the theory of statistical inference assumes a fixed collection of hypotheses to be tested, or learning algorithms to be applied, selected non-adaptively before the data are gathered, whereas in practice data is shared and reused with hypotheses and new analyses being generated on the basis of data exploration and the outcomes of previous analyses. In this work we initiate a principled study of how to guarantee the validity of statistical inference in adaptive data analysis. As an instance of this problem, we propose and investigate the question of estimating the expectations of m adaptively chosen functions on an unknown distribution given n random samples. We show that, surprisingly, there is a way to estimate an exponential in n number of expectations accurately even if the functions are chosen adaptively. This gives an exponential improvement over standard empirical estimators that are limited to a linear number of estimates. Our result follows from a general technique that counter-intuitively involves actively perturbing and coordinating the estimates, using techniques developed for privacy preservation. We give additional applications of this technique to our question.},
annote = {La probl{\'{e}}matique: si l'on calcule plein d'estimateurs (des statistical query) sur le m{\^{e}}me jeu de donn{\'{e}}es, ils sont tr{\`{e}}s corr{\'{e}}l{\'{e}}s et le false discovery rate est {\'{e}}lev{\'{e}}. Pareil, si l'on fait calibre des param{\`{e}}tres de plusieurs algorithmes sur un seul jeu de donn{\'{e}}es: le pouvoir de g{\'{e}}n{\'{e}}ralisation est faible.

Article sur le pouvoir de g{\'{e}}n{\'{e}}ralisation des algorithmes differentially private.
Quelques mots sur l'utilit{\'{e}} pour le machine learning, puis utilit{\'{e}} pour les tests d'hypoth{\`{e}}ses. Gr{\^{a}}ce {\`{a}} ces algorithmes, on peut cr{\'{e}}er m estimateurs (m grand) tout en utilisant peu de donn{\'{e}}es et en garantissant que leur valeur est proche de la v{\'{e}}rit{\'{e}}. L'utilit{\'{e}} principale est que ces algorithmes n'ont pas besoin d'un nombre lin{\'{e}}airement croissant (en m) d'observations pour garantir la convergence.},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.2664v2},
author = {Dwork, Cynthia and Feldman, Vitaly and Reingold, Omer and Hardt, Moritz and Roth, Aaron and Pitassi, Toniann},
eprint = {arXiv:1411.2664v2},
file = {:home/charles/Documents/Mendeley Desktop/Dwork et al. - 2015 - Preserving Statistical Validity in Adaptive Data Analysis.pdf:pdf},
keywords = {Differential privacy,Multiple testing},
mendeley-tags = {Differential privacy,Multiple testing},
title = {{Preserving Statistical Validity in Adaptive Data Analysis}},
year = {2015}
}
@article{Penna2009,
abstract = {In this paper we develop a complete analytical framework based on Random Matrix Theory for the performance evaluation of Eigenvalue-based Detection. While, up to now, analysis was limited to false-alarm probability, we have obtained an analytical expression also for the probability of missed detection, by using the theory of spiked population models. A general scenario with multiple signals present at the same time is considered. The theoretical results of this paper allow to predict the error probabilities, and to set the decision threshold accordingly, by means of a few mathematical formulae. In this way the design of an eigenvalue-based detector is made conceptually identical to that of a traditional energy detector. As additional results, the paper discusses the conditions of signal identifiability for single and multiple sources. All the analytical results are validated through numerical simulations, covering also convergence, identifiabilty and non-Gaussian practical modulations.},
annote = {Pour savoir si un signal n'est que du bruit ou non.
Utile pour savoir si la diff{\'{e}}rence entre un signal et sa reconstruction n'est que du bruit ou il reste des composantes.},
archivePrefix = {arXiv},
arxivId = {0907.1523},
author = {Penna, Federico and Garello, Roberto},
eprint = {0907.1523},
file = {:home/charles/Documents/Mendeley Desktop/Penna, Garello - 2009 - Theoretical Performance Analysis of Eigenvalue-based Detection.pdf:pdf},
keywords = {Eigenvalue-based dectection,Hypotheses testing,Signal processing},
mendeley-tags = {Eigenvalue-based dectection,Hypotheses testing,Signal processing},
pages = {31},
title = {{Theoretical Performance Analysis of Eigenvalue-based Detection}},
url = {http://arxiv.org/abs/0907.1523},
year = {2009}
}
@article{Nadler2011,
abstract = {Roy's largest root is a common test in multivariate analysis of variance (MANOVA), with applications in several other problems, such as signal detection in noise. In this paper, assuming multivariate Gaussian observations, we derive a simple yet accurate approxima- tion for the distribution of Roy's largest root test, in the extreme case of concentrated non-centrality, where the signal or difference between groups is concentrated in a single direction. Our main result is that in the MANOVA setting, up to centering and scaling, Roy's largest root test approximately follows a non-central F distribution whereas in the signal detection application, it approximately follows a modified central F distribution (of the form (s + $\chi$2 a)/$\chi$2 estimates of sample size required to detect a given (rank-one) group difference by this test, both of which are important quantities in hypothesis-driven research.},
author = {Nadler, Boaz and Johnstone, Iain M.},
file = {:home/charles/Documents/Mendeley Desktop/Nadler, Johnstone - 2011 - On distribution of Roy's largest root test in Maanova and signal detection of noise.pdf:pdf},
title = {{On distribution of Roy's largest root test in Maanova and signal detection of noise}},
year = {2011}
}
@article{Rabiner1989,
abstract = {This tutorial provides an overview of the basic theory of hidden$\backslash$nMarkov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and$\backslash$ngives practical details on methods of implementation of the theory along$\backslash$nwith a description of selected applications of the theory to distinct$\backslash$nproblems in speech recognition. Results from a number of original$\backslash$nsources are combined to provide a single source of acquiring the$\backslash$nbackground required to pursue further this area of research. The author$\backslash$nfirst reviews the theory of discrete Markov chains and shows how the$\backslash$nconcept of hidden states, where the observation is a probabilistic$\backslash$nfunction of the state, can be used effectively. The theory is$\backslash$nillustrated with two simple examples, namely coin-tossing, and the$\backslash$nclassic balls-in-urns system. Three fundamental problems of HMMs are$\backslash$nnoted and several practical techniques for solving these problems are$\backslash$ngiven. The various types of HMMs that have been studied, including$\backslash$nergodic as well as left-right models, are described},
author = {Rabiner, L.R.},
doi = {10.1109/5.18626},
file = {:home/charles/Documents/Mendeley Desktop/Rabiner - 1989 - A tutorial on hidden Markov models and selected applications in speech recognition.pdf:pdf},
isbn = {1558601244},
issn = {00189219},
journal = {Proceedings of the IEEE},
number = {2},
pages = {257--286},
pmid = {21920608},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
volume = {77},
year = {1989}
}
@inproceedings{Pavlovic2000,
abstract = {The human figure exhibits complex and rich dynamic behavior that is both nonlinear and time-varying. Effective models of human dynamics can be learned from motion capture data using switching linear dynamic system (SLDS) models. We present results for human motion synthesis, classification, and visual tracking using learned SLDS models. Since ex- act inference in SLDS is intractable, we present three approximate inference algorithms and compare their performance. In particular, a new variational inference algorithm is obtained by casting the SLDS model as a Dynamic Bayesian Network. Classification experiments show the superiority of SLDS over conventionalHMM's for our problem domain.},
address = {Denver, United States},
annote = {cet articke est une introduction, pas plus. N{\'{e}}cessite plus d'approfondissements.
Toute les r{\'{e}}f{\'{e}}rences m{\'{e}}riteraient d'{\^{e}}tre lues.
Il est impl{\'{e}}ment{\'{e}} en R. C'est du bay{\'{e}}sien compliqu{\'{e}}.},
author = {Pavlovic, V. and Rehg, J. M. and MacCormick, J.},
booktitle = {Advances in Neural Information Processing Systems 13 (NIPS)},
file = {:home/charles/Documents/Mendeley Desktop/Pavlovic, Rehg, MacCormick - 2000 - Learning Switching Linear Models of Human Motion.pdf:pdf},
pages = {981--987},
title = {{Learning Switching Linear Models of Human Motion}},
year = {2000}
}
@article{andreou2002detecting,
abstract = {The paper evaluates the performance of several recently proposed tests for structural breaks in the conditional variance dynamics of asset returns. The tests apply to the class of ARCH and SV type processes as well as data-driven volatility estimators using high-frequency data. In addition to testing for the presence of breaks, the statistics identify the number and location of multiple breaks. We study the size and power of the new tests for detecting breaks in the conditional variance under various realistic univariate heteroscedastic models, change-point hypotheses and sampling schemes. The paper concludes with an empirical analysis using data from the stock and FX markets for which we find multiple breaks associated with the Asian and Russian financial crises. These events resulted in changes in the dynamics of volatility of asset returns in the samples prior and post the breaks. Copyright {\textcopyright} 2002 John Wiley {\&} Sons, Ltd.},
annote = {From Duplicate 1 (Detecting multiple breaks in financial market volatility dynamics - Andreou, Elena; Ghysels, Eric)

article sur la segmentation en finance},
author = {Andreou, Elena and Ghysels, Eric},
doi = {10.1002/jae.684},
file = {:home/charles/Documents/Mendeley Desktop/Andreou, Ghysels - 2002 - Detecting multiple breaks in financial market volatility dynamics.pdf:pdf},
isbn = {3572892430},
issn = {08837252},
journal = {Journal of Applied Econometrics},
number = {5},
pages = {579--600},
publisher = {Wiley Online Library},
title = {{Detecting multiple breaks in financial market volatility dynamics}},
volume = {17},
year = {2002}
}
@article{arlot2012kernel,
abstract = {We tackle the change-point problem with data belonging to a general set. We propose a penalty for choosing the number of change-points in the kernel-based method of Harchaoui and Capp{\'{e}} (2007). This penalty generalizes the one proposed for one dimensional signals by Lebarbier (2005). We prove it satisfies a non-asymptotic oracle inequality by showing a new concentration result in Hilbert spaces. Experiments on synthetic and real data illustrate the accuracy of our method, showing it can detect changes in the whole distribution of data, even when the mean and variance are constant. Our algorithm can also deal with data of complex nature, such as the GIST descriptors which are commonly used for video temporal segmentation.},
annote = {From Duplicate 1 (Kernel change-point detection - Arlot, Sylvain; Celisse, Alain; Harchaoui, Zaid)

segmentation.Le signal est mapp{\'{e}} dans un rkhs puis approximation constante par morceaux},
author = {Arlot, S. and Celisse, A. and Harchaoui, Z.},
file = {:home/charles/Documents/Mendeley Desktop/Arlot, Celisse, Harchaoui - 2012 - Kernel change-point detection.pdf:pdf},
journal = {arXiv preprint arXiv:1202.3878},
keywords = {Learning/Statistics {\&} Optimisation,Theory {\&} Algorithms},
number = {0000},
pages = {1--26},
title = {{Kernel change-point detection}},
volume = {1},
year = {2012}
}
@article{gretton2012kernel,
abstract = {We propose a framework for analyzing and comparing distributions, which we use to construct statistical tests to determine if two samples are drawn from different distributions. Our test statistic is the largest difference in expectations over functions in the unit ball of a reproducing kernel Hilbert space (RKHS), and is called the maximum mean discrepancy (MMD). We present two distribution-free tests based on large deviation bounds for the MMD, and a third test based on the asymptotic distribution of this statistic. The MMD can be computed in quadratic time, although efficient linear time approximations are available. Our statistic is an instance of an integral probability metric, and various classical metrics on distributions are obtained when alternative function classes are used in place of an RKHS. We apply our two-sample tests to a variety of problems, including attribute matching for databases using the Hungarian marriage method, where they perform strongly. Excellent performance is also obtained when comparing distributions over graphs, for which these are the first such tests.},
author = {Gretton, A. and Borgwardt, K. M. and Rasch, M. J. and Sch{\"{o}}lkopf, B. and Smola, A.},
file = {:home/charles/Documents/Mendeley Desktop/Gretton - 2012 - A Kernel Two-Sample Test.pdf:pdf},
journal = {Journal of Machine Learning Research},
number = {1},
pages = {723--773},
title = {{A kernel two-sample test}},
volume = {13},
year = {2012}
}
@article{Nason2000,
abstract = {This paper defines and studies a new class of non-stationary random processes con- structed from discrete non-decimated wavelets which generalizes the Cramer (Fourier) representation of stationary time series. We define an evolutionary wavelet spectrum (EWS) which quantifies how process power varies locally over time and scale. We show how the EWS may be rigorously estimated by a smoothed wavelet periodogram and how both these quantities may be inverted to provide an estimable time-localized autocovariance. We illustrate our theory with a pedagogical example based on discrete non-decimated Haar wavelets and also a real medical time series example.},
author = {Nason, Guy P. and von Sachs, Rainer and Kroisandt, Gerald},
file = {:home/charles/Documents/Mendeley Desktop/Nason, von Sachs, Kroisandt - 2000 - Wavelet processes and adaptive estimation of the evolutionary wavelet spectrum.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
keywords = {Local stationarity,Non-linear wavelet shrinkage,Non-stationary time series,Wavelet,Wavelet processes,Wavelet spectrum,founding article,periodogram},
mendeley-tags = {Local stationarity,Non-linear wavelet shrinkage,Non-stationary time series,Wavelet,Wavelet processes,Wavelet spectrum,founding article,periodogram},
number = {2},
pages = {271--292},
title = {{Wavelet processes and adaptive estimation of the evolutionary wavelet spectrum}},
volume = {62},
year = {2000}
}
@inproceedings{chen1998speaker,
address = {Landsdowne, VA},
annote = {article tr{\`{e}}s cit{\'{e}} segmentation en fenetre glissante et en bottum up
signal iid},
author = {Chen, S. S. and Gopalakrishnan, P. S.},
booktitle = {Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop},
file = {:home/charles/Documents/Mendeley Desktop/Speaker, environment and channel change detection and clustering via the bayesian information criterion.pdf:pdf},
organization = {Virginia, USA},
pages = {8},
title = {{Speaker, environment and channel change detection and clustering via the bayesian information criterion}},
year = {1998}
}
@article{cho2014multiple,
annote = {Pour un article sur la segmentation en finance.
Binary segmentation
Cumulative sum statistic
High dimensional time series
Locally stationary wavelet model
Multiple-change-point detection
Thresholding},
author = {Cho, Haeran and Fryzlewicz, Piotr},
file = {:home/charles/Documents/Mendeley Desktop/Cho, Fryzlewicz - 2014 - Multiple-change-point detection for high dimensional time series via sparsified binary segmentation.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {2},
pages = {475--507},
publisher = {Wiley Online Library},
title = {{Multiple-change-point detection for high dimensional time series via sparsified binary segmentation}},
volume = {77},
year = {2014}
}
@inproceedings{harchaoui2007retrospective,
abstract = {This contribution proposes an extension of the classic dynamic programming algorithm for detecting jumps in noisily observed piecewise-constant signals. The proposed algorithm operates (virtually) in a reproducing kernel Hilbert space through the use of an arbitrary kernel mapping. The resulting approach provides a computationally efficient an versatile tool for segmenting complex signals whose structure is not appropriately captured by standard parametric models.},
address = {Madison, Wisconsin, USA},
annote = {kernel change point detection par optimisation globale. Il dit qu'une approche par fen{\^{e}}tre demande beaucoup de tuning, et ne prennent pas en compte tout le signal d'un coup.},
author = {Harchaoui, Z. and Capp{\'{e}}, O.},
booktitle = {Proceedings of the IEEE/SP Workshop on Statistical Signal Processing},
doi = {10.1109/SSP.2007.4301363},
file = {:home/charles/Documents/Mendeley Desktop/Retrospective multiple change-point estimation with kernels.pdf:pdf},
isbn = {142441198X},
pages = {768--772},
title = {{Retrospective mutiple change-point estimation with kernels}},
year = {2007}
}
@article{guedon:inria-00311634,
abstract = {This paper addresses the retrospective or off-line multiple change-point detection problem. Multiple change-point models are here viewed as latent structure models and the focus is on inference concerning the latent segmentation space. Methods for exploring the space of possible segmentations of a sequence for a fixed number of change points may be divided into two categories: (i) enumeration of segmentations, (ii) summary of the possible segmentations in change-point or segment profiles. Concerning the first category, a dynamic programming algorithm for computing the top $\backslash${\$}\backslash{\$}N$\backslash${\$}\backslash{\$} N most probable segmentations is derived. Concerning the second category, a forward-backward dynamic programming algorithm and a smoothing-type forward-backward algorithm for computing two types of change-point and segment profiles are derived. The proposed methods are mainly useful for exploring the segmentation space for successive numbers of change points and provide a set of assessment tools for multiple change-point models that can be applied both in a non-Bayesian and a Bayesian framework. We show using examples that the proposed methods may help to compare alternative multiple change-point models (e.g. Gaussian model with piecewise constant variances or global variance), predict supplementary change points, highlight overestimation of the number of change points and summarize the uncertainty concerning the position of change points.},
annote = {Article sur quelques techniques de programmation dynamiques.
Les fa{\c{c}}ons de parcourir l'ensemble des partitions.},
author = {Gu{\'{e}}don, Y.},
doi = {10.1007/s00180-013-0422-9},
file = {:home/charles/Documents/Mendeley Desktop/Gu{\'{e}}don - 2013 - Exploring the latent segmentation space for the assessment of multiple change-point models(2).pdf:pdf},
journal = {Computational Statistics},
keywords = {Dynamic programming algorithm,Latent structure model,Multiple change-point detection,Plant structure analysis,Smoothing algorithm},
number = {6},
pages = {2641--2678},
title = {{Exploring the latent segmentation space for the assessment of multiple change-point models}},
type = {Research Report},
url = {https://hal.inria.fr/inria-00311634},
volume = {28},
year = {2013}
}
@article{keogh2004segmenting,
annote = {Pour trouver des r{\'{e}}f{\'{e}}rences sur la segmentations et tout ce qui s'est fait sans le pass{\'{e}}. Donne des refs sur les techniques de base de la segmentation.},
author = {Keogh, E. and Chu, S. and Hart, D. and Pazzani, M.},
doi = {10.1142/9789812565402_0001},
file = {:home/charles/Documents/Mendeley Desktop/Keogh et al. - 2004 - Segmenting time series A survey and novel approach.pdf:pdf},
journal = {Data Mining in Time Series Databases},
number = {1},
pages = {1--22},
publisher = {World Scientific Publishing},
title = {{Segmenting time series: a survey and novel approach}},
volume = {57},
year = {2004}
}
@article{bellman1956routing,
annote = {Article fondateur pour la programmation dynamique.},
author = {Bellman, Richard},
journal = {Quartely of Applied Mathematics},
keywords = {dynamic programming},
mendeley-tags = {dynamic programming},
pages = {87--90},
title = {{On a routing problem}},
volume = {16},
year = {1958}
}
@article{benjamini2001control,
author = {Benjamini, Yoav and Yekutieli, Daniel},
journal = {Annals of statistics},
pages = {1165--1188},
publisher = {JSTOR},
title = {{The control of the false discovery rate in multiple testing under dependency}},
year = {2001}
}
@inproceedings{eric2008testing,
author = {Eric, Moulines and Bach, Francis R and Harchaoui, Za{\"{i}}d},
booktitle = {Advances in Neural Information Processing Systems},
pages = {609--616},
title = {{Testing for homogeneity with kernel fisher discriminant analysis}},
year = {2008}
}
@article{gretton2008kernel,
author = {Gretton, Arthur and Borgwardt, Karsten and Rasch, Malte J and Scholkopf, Bernhard and Smola, Alexander J},
journal = {arXiv preprint arXiv:0805.2368},
title = {{A kernel method for the two-sample problem}},
year = {2008}
}
@inproceedings{blazek2001novel,
annote = {segmentation qui utilise le CUMSUM approche param{\'{e}}trique pour l'exemple},
author = {Blazek, Rudolf B and Kim, Hongjoong and Rozovskii, Boris and Tartakovsky, Alexander},
booktitle = {Proceedings of IEEE systems, man and cybernetics information assurance workshop},
organization = {Citeseer},
pages = {220--226},
title = {{A novel approach to detection of denial-of-service attacks via adaptive sequential and batch-sequential change-point detection methods}},
year = {2001}
}
@inproceedings{keogh2001online,
abstract = {In recent years, there has been an explosion of interest in mining time-series databases. As with most computer science problems, representation of the data is the key to efficient and effective solutions. One of the most commonly used representations is piecewise linear approximation. This representation has been used by various researchers to support clustering, classification, indexing and association rule mining of time-series data. A variety of algorithms have been proposed to obtain this representation, with several algorithms having been independently rediscovered several times. In this paper, we undertake the first extensive review and empirical comparison of all proposed techniques. We show that all these algorithms have fatal flaws from a data-mining perspective. We introduce a novel algorithm that we empirically show to be superior to all others in the literature.},
address = {San Jose, California, USA},
annote = {pour une r{\'{e}}f{\'{e}}rence sur les techniques {\`{a}} fen{\^{e}}tres, bottom-up et top down (sur une grille dyadique) en segmentation.},
author = {Keogh, E. and Chu, S. and Hart, D. and Pazzani, M.},
booktitle = {Proceedings of the IEEE International Conference on Data Mining (ICDM)},
doi = {10.1109/ICDM.2001.989531},
isbn = {0-7695-1119-8},
issn = {15504786},
pages = {289--296},
title = {{An online algorithm for segmenting time series}},
year = {2001}
}
@article{bai2003computation,
annote = {Sur la programmation dynamique et l'application {\`{a}} la segmentation},
author = {Bai, J. and Perron, P.},
file = {:home/charles/Documents/Mendeley Desktop/Bai, Perron - 2003 - Computation and analysis of multiple structural change models.pdf:pdf},
journal = {Journal of applied econometrics},
keywords = {dynamic programming},
mendeley-tags = {dynamic programming},
number = {1},
pages = {1--22},
title = {{Computation and analysis of multiple structural change models}},
volume = {18},
year = {2003}
}
@article{desobry2005online,
annote = {d{\'{e}}tection de ruptures avec un noyau, des fen{\^{e}}tres, un mod{\`{e}}le param{\'{e}}trique.},
author = {Desobry, F. and Davy, M. and Doncarli, C.},
file = {:home/charles/Documents/Mendeley Desktop/Desobry, Davy, Doncarli - 2005 - An online kernel change detection algorithm.pdf:pdf},
journal = {IEEE Transactions on Signal Processing},
number = {8},
pages = {2961--2974},
publisher = {IEEE},
title = {{An online kernel change detection algorithm}},
volume = {53},
year = {2005}
}
@article{hubert1985comparing,
annote = {article qui explique les divers moyens de comparer deux partitions. rand index, autres mesures},
author = {Hubert, Lawrence and Arabie, Phipps},
journal = {Journal of classification},
number = {1},
pages = {193--218},
publisher = {Springer},
title = {{Comparing partitions}},
volume = {2},
year = {1985}
}
@inproceedings{Kifer:2004:DCD:1316689.1316707,
address = {Toronto, Canada},
annote = {M{\'{e}}thode {\`{a}} fen{\^{e}}tres.},
author = {Kifer, Daniel and Ben-David, Shai and Gehrke, Johannes},
booktitle = {Proceedings of the Thirtieth International Conference on Very Large Data Bases (VLDB) - Volume 30},
file = {:home/charles/Documents/Mendeley Desktop/Kifer, Ben-David, Gehrke - 2004 - Detecting Change in Data Streams.pdf:pdf},
isbn = {0-12-088469-0},
pages = {180--191},
publisher = {VLDB Endowment},
series = {VLDB '04},
title = {{Detecting Change in Data Streams}},
url = {http://dl.acm.org/citation.cfm?id=1316689.1316707},
year = {2004}
}
@article{siegmund1995using,
annote = {segmentation avec GLR (et comparaison avec cumsum) pour l'exemple.
On ne comprend rien.},
author = {Siegmund, David and Venkatraman, E S},
journal = {The Annals of Statistics},
pages = {255--271},
publisher = {JSTOR},
title = {{Using the generalized likelihood ratio statistic for sequential detection of a change-point}},
year = {1995}
}
@article{Fondamentales2012,
author = {Fondamentales, Sciences and Domenech, Trystan},
file = {:home/charles/Documents/Mendeley Desktop/Fondamentales, Domenech - 2012 - Doctorat ParisTech.pdf:pdf},
journal = {Sciences-New York},
title = {{Doctorat ParisTech}},
year = {2012}
}
@article{Fu2001,
abstract = {Time series data are difficult to manipulate. When they can be transformed into meaningful symbols, it becomes an easy task to query and understand them. While most recent works in time series query only concentrate on how to identify a given pattern from a time series, they do not consider the problem of identifying a suitable set of time points based upon which the time series can be segmented in accordance with a given set of pattern templates, e.g., a set of technical analysis patterns for stock analysis. On the other hand, using fixed length segmentation is only a primitive approach to such kind of problem and hence a dynamic approach is preferred so that the time series can be segmented flexibly and effectively. In view of the fact that such a segmentation problem is actually an optimization problem and evolutionary computation is an appropriate tool to solve it, we propose an evolutionary segmentation algorithm in this paper. Encouraging experimental results in segmenting the Hong Kong Hang Seng Index using 22 technical analysis patterns are reported},
annote = {pas clair.
pas th{\'{e}}orique},
author = {Fu, Tak-Chung Fu Tak-Chung and Chung, Fu-lai Chung Fu-lai and Ng, V. and Luk, R.},
doi = {10.1109/CEC.2001.934422},
file = {:home/charles/Documents/Mendeley Desktop/Fu et al. - 2001 - Evolutionary segmentation of financial time series into subsequences.pdf:pdf},
isbn = {0-7803-6657-3},
journal = {Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546)},
title = {{Evolutionary segmentation of financial time series into subsequences}},
volume = {1},
year = {2001}
}
@article{Hubert1989,
abstract = {An original segmentation procedure hydrometeorology series is setailed. From the beginning of this century, the results of rainfall and discharge series analysis exhibit a West African climatological evolution in successive stages. These stages, separated by jumps, come within more and more arid general tendency. The length of the sequences between the jumps are 9 to more than 19 years long. These climatological sequences, computed from various time series are concomitant and then have a regional significance.},
annote = {constant par morceaux},
author = {Hubert, Pierre and Carbonnel, Jean Pierre and Chaouche, Ali},
doi = {10.1016/0022-1694(89)90197-2},
file = {:home/charles/Documents/Mendeley Desktop/Hubert, Carbonnel, Chaouche - 1989 - Segmentation des s{\'{e}}ries hydrom{\'{e}}t{\'{e}}orologiques — application {\`{a}} des s{\'{e}}ries de pr{\'{e}}cipitations.pdf:pdf},
issn = {00221694},
journal = {Journal of Hydrology},
number = {3-4},
pages = {349--367},
title = {{Segmentation des s{\'{e}}ries hydrom{\'{e}}t{\'{e}}orologiques — application {\`{a}} des s{\'{e}}ries de pr{\'{e}}cipitations et de d{\'{e}}bits de l'afrique de l'ouest}},
volume = {110},
year = {1989}
}
@article{Gedikli2010,
abstract = {For the offline segmentation of long hydrometeological time series, a new algorithm which combines the dynamic programming with the recently introduced remaining cost concept of branch-and-bound approach is developed. The algorithm is called modified dynamic programming (mDP) and segments the time series based on the first-order statistical moment. Experiments are performed to test the algorithm on both real world and artificial time series comprising of hundreds or even thousands of terms. The experiments show that the mDP algorithm produces accurate segmentations in much shorter time than previously proposed segmentation algorithms.},
annote = {constant par morceaux
ne marche pas.},
author = {Gedikli, Abdullah and Aksoy, Hafzullah and Unal, N. Erdem and Kehagias, Athanasios},
doi = {10.1007/s00477-009-0335-x},
file = {:home/charles/Documents/Mendeley Desktop/Gedikli et al. - 2010 - Modified dynamic programming approach for offline segmentation of long hydrometeorological time series.pdf:pdf},
issn = {14363240},
journal = {Stochastic Environmental Research and Risk Assessment},
keywords = {Change point,Dynamic programming,Modified dynamic programming,Offline segmentation,Remaining cost concept,Time series},
number = {5},
pages = {547--557},
title = {{Modified dynamic programming approach for offline segmentation of long hydrometeorological time series}},
volume = {24},
year = {2010}
}
@article{Moskvina2003,
abstract = {This paper presents a novel framework for three-dimensional model-based tracking. Graphical rendering technology is combined with constrained active contour tracking to create a robust wire-frame tracking system. It operates in real time at video frame rate (25 Hz) on standard hardware. It is based on an internal CAD model of the object to be tracked which is rendered using a binary space partition tree to perform hidden line removal. The visible edge features are thus identified online at each frame and correspondences are found in the video feed. A Lie group formalism is used to cast the motion computation problem into simple geometric terms so that tracking becomes a simple optimization problem solved by means of iterative reweighted least squares. A visual servoing system constructed using this framework is presented together with results showing the accuracy of the tracker. The system also incorporates real-time online calibration of internal camera parameters. The paper then describes how this tracking system has been extended to provide a general framework for tracking in complex configurations, including the use of multiple cameras, the tracking of structures with articulated components, or of multiple structures with constraints. The methodology used to achieve this exploits the simple geometric nature of the Lie group formalism which renders the constraints linear and homogeneous. The adjoint representation of the group is used to transform measurements into common coordinate frames. The constraints are then imposed by means of Lagrange multipliers. Results from a number of experiments performed using this framework are presented and discussed.},
annote = {L'algorithme d{\'{e}}pend de param{\`{e}}tres difficiles {\`{a}} tuner, notament le lag de la matrice de trajectoire.
Il faut faire plus de tests.

Il faut inverser une matrice {\`{a}} chaque lag: c'est long},
author = {Moskvina, Valentina},
doi = {10.1081/SAC-120017494},
file = {:home/charles/Documents/Mendeley Desktop/Moskvina - 2003 - An Algorithm Based on Singular Spectrum Analysis for Change-Point Detection.pdf:pdf},
issn = {0361-0918},
journal = {Communications in Statistics: Simulation and Computation},
keywords = {0,29 20 8741,44,Change-point detection,Sequential algorithm,Singular value decomposition,Singular-spectrum analysis,anatoly zhigljavsky,cardiff,cardiff uni-,change-point detection,correspondence,fax,school of mathematics,senghennydd rd,sequential algorithm,singular value decomposition,singular-spectrum analysis,uk cf24 4yh,versity},
mendeley-tags = {Change-point detection,Sequential algorithm,Singular value decomposition,Singular-spectrum analysis},
number = {2},
pages = {319--352},
title = {{An Algorithm Based on Singular Spectrum Analysis for Change-Point Detection}},
url = {http://www.informaworld.com/openurl?genre=article{\&}doi=10.1081/SAC-120017494{\&}magic=crossref{\%}7C{\%}7CD404A21C5BB053405B1A640AFFD44AE3},
volume = {32},
year = {2003}
}
@article{Maidstone2013,
annote = {param{\'{e}}trique ({\`{a}} base de log likelihood)},
author = {Maidstone, R.},
file = {:home/charles/Documents/Mendeley Desktop/Maidstone - 2013 - Efficient Analysis of Complex Changepoint Models.pdf:pdf},
pages = {34},
title = {{Efficient Analysis of Complex Changepoint Models}},
year = {2013}
}
@article{Kawahara2009,
abstract = {Change-point detection is the problem of discovering time points at which properties of time-series data change. This covers a broad range of real-world problems and has been actively discussed in the community of statistics and data mining. In this paper, we present a novel non-parametric approach to detecting the change of probability distribu- tions of sequence data. Our key idea is to estimate the ratio of probability densities, not the probability densities them- selves. This formulation allows us to avoid non-parametric density estimation, which is known to be a difficult prob- lem. We provide a change-point detection algorithm based on direct density-ratio estimation that can be computed very efficiently in an online manner. The usefulness of the pro- posed method is demonstrated through experiments using artificial and real datasets.},
annote = {m{\'{e}}thode {\`{a}} fen{\^{e}}tres
liste de datasets synth{\'{e}}tiques},
author = {Kawahara, Yoshinobu},
file = {:home/charles/Documents/Mendeley Desktop/Kawahara - 2009 - Change-Point Detection in Time-Series Data by Direct Density-Ratio Estimation.pdf:pdf},
isbn = {9781615671090},
issn = {15524981},
journal = {Proceedings of the 2009 SIAM International Conference on Data Mining (ICDM)},
keywords = {change-point detection,direct density-ratio,estimation,kernel methods,time-series data},
pages = {389--400},
title = {{Change-Point Detection in Time-Series Data by Direct Density-Ratio Estimation}},
year = {2009}
}
@inproceedings{Vert2010,
address = {Vancouver, Canada},
annote = {Pour le constant par morceaux seulement.
P{\'{e}}nalisation sur la variation totale de l'approximation.
L'article insiste sur le fait qu'il est utile pour les grandes dimensions.},
author = {Vert, J.-P. and Bleakley, K.},
booktitle = {Advances in Neural Information Processing Systems 23 (NIPS 2010)},
file = {:home/charles/Documents/Mendeley Desktop/Vert, Bleakley - 2010 - Fast detection of multiple change-points shared by many signals using group LARS.pdf:pdf},
pages = {2343--2351},
title = {{Fast detection of multiple change-points shared by many signals using group LARS}},
volume = {1},
year = {2010}
}
@article{Davidson1987,
abstract = {The local power of test statistics is analyzed by extending the notion of Pitman sequences to sequences of data-generating processes (DGP's) that approach the null hypothesis without necessarily satisfying the alternative. A space of probability densities is defined and endowed with the structure of an infinite-dimensional Hilbert manifold, which permits a geometrical interpretation of hypothesis testing. The three classical test statistics-LR, Wald, and LM-are shown to tend asymptotically to the same random variable under all sequences of local DGP's. The power of these statistics is seen to depend on the null, the alternative, and the sequence of DGP's in a simple and geometrically intuitive way. Moreover, for any test statistic that is asymptotically chi-squared under the null, there exists an "implicit alternative hypothesis" against which that statistic will have highest power, and which coincides with the explicit alternative for the classical test statistics.},
author = {Davidson, Russell and MacKinnon, James G.},
file = {:home/charles/Documents/Mendeley Desktop/Davidson, MacKinnon - 1987 - Implicit Alternatives and the Local Power of Test Statistics.pdf:pdf},
journal = {Econometrica},
keywords = {Classical test statistics,Hilbert mani- fold,Pitman sequence,hypothesis testing,implicit alternatives},
mendeley-tags = {Classical test statistics,Hilbert mani- fold,Pitman sequence,hypothesis testing,implicit alternatives},
number = {6},
pages = {1305--1329},
title = {{Implicit Alternatives and the Local Power of Test Statistics}},
volume = {55},
year = {1987}
}
@article{E.Brodsky1999,
abstract = {A new method for segmentation of the EEG, based on a nonparametric statistical analysis, is proposed. A nonparametric approach was chosen because it minimises the need for a priori information about a signal. The method provides detection of change-points (quasi-stationary segments' boundaries) in almost any EEG characteristic for a given level of false alarm probability. The method was applied to 8-channels spontaneous EEG recordings obtained from 12 subjects in eyes closed and eyes open conditions to detect rapid fluctuations of the alpha rhythm power. After preliminary adjustment of false alarm probability values all the recordings were analysed in unsupervised regime with the same parameters. From 15 to 1 19 change-points were found per minute and EEG channel. Automatically detected change-points were in good correspondence with visual estimation of the instants of change in alpha activity.},
annote = {pas clair
a pas l'air tr{\`{e}}s efficace.},
author = {{E. Brodsky}, Boris and {S. Darkhovsky}, Boris and {Ya. Kaplan}, Alexander and {L. Shishkin}, Sergei},
doi = {10.1016/S0169-2607(98)00079-0},
file = {:home/charles/Documents/Mendeley Desktop/E. Brodsky et al. - 1999 - A nonparametric method for the segmentation of the EEG.pdf:pdf},
isbn = {0169-2607 (Print)},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Alpha rhythm,Change-point detection,EEG segmentation,Fluctuations},
number = {2},
pages = {93--106},
pmid = {10505965},
title = {{A nonparametric method for the segmentation of the EEG}},
volume = {60},
year = {1999}
}
@article{Azami2014,
abstract = {In numerous signal processing applications, non-stationary signals should be segmented to piece-wise stationary epochs before being further analyzed. In this article, an enhanced segmentation method based on fractal dimension (FD) and evolutionary algorithms (EAs) for non-stationary signals, such as electroencephalogram (EEG), magnetoencephalogram (MEG) and electromyogram (EMG), is proposed. In the proposed approach, discrete wavelet transform (DWT) decomposes the signal into orthonormal time series with different frequency bands. Then, the FD of the decomposed signal is calculated within two sliding windows. The accuracy of the segmentation method depends on these parameters of FD. In this study, four EAs are used to increase the accuracy of segmentation method and choose acceptable parameters of the FD. These include particle swarm optimization (PSO), new PSO (NPSO), PSO with mutation, and bee colony optimization (BCO). The suggested methods are compared with other most popular approaches (improved nonlinear energy operator (INLEO), wavelet generalized likelihood ratio (WGLR), and Varri's method) using synthetic signals, real EEG data, and the difference in the received photons of galactic objects. The results demonstrate the absolute superiority of the suggested approach. ?? 2014.},
annote = {Marche pas. Les r{\'{e}}p{\'{e}}sentations ne sont pas claires.},
author = {Azami, Hamed and Hassanpour, Hamid and Escudero, Javier and Sanei, Saeid},
doi = {10.1016/j.jare.2014.03.004},
file = {:home/charles/Documents/Mendeley Desktop/Azami et al. - 2014 - An intelligent approach for variable size segmentation of non-stationary signals.pdf:pdf},
issn = {20901232},
journal = {Journal of Advanced Research},
keywords = {Adaptive segmentation,Discrete wavelet transform,Evolutionary algorithm,Fractal dimension,Particle swarm optimization},
publisher = {Cairo University},
title = {{An intelligent approach for variable size segmentation of non-stationary signals}},
url = {http://dx.doi.org/10.1016/j.jare.2014.03.004},
year = {2014}
}
@article{Friedman1979,
abstract = {Multivariate generalizations of the Wald-Wolfowitz runs statistic and the Smirnov maximum deviation statistic for the two-sample problem are presented. They are based on the minimal spanning tree of the pooled sample points. Some null distribution result are derived and a simulation study of power is reported.},
author = {Friedman, Jerome H and Rafsky, Lawrence C},
file = {:home/charles/Documents/Mendeley Desktop/Friedman, Rafsky - 1979 - Multivariate Generalizations of Wald-Wolfowitz and Smirnov two-sample tests.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {Smirnov test,Wald-Wolfowitz test,minimal spanning tree,multivariate two-sample test,non-parametric},
mendeley-tags = {Smirnov test,Wald-Wolfowitz test,minimal spanning tree,multivariate two-sample test,non-parametric},
number = {4},
pages = {697--717},
title = {{Multivariate Generalizations of Wald-Wolfowitz and Smirnov two-sample tests}},
volume = {7},
year = {1979}
}
@article{Clemencon2009,
author = {Clemencon, Stephan and Depecker, Marine and Vayatis, Nicolas},
file = {:home/charles/Documents/Mendeley Desktop/Clemencon, Depecker, Vayatis - 2009 - AUC optimization and the two-sample problem.pdf:pdf},
isbn = {9781615679119},
journal = {Advances in neural {\ldots}},
pages = {1--9},
title = {{AUC optimization and the two-sample problem}},
url = {http://papers.nips.cc/paper/3838-auc-optimization-and-the-two-sample-problem},
year = {2009}
}
@article{Lung-Yut-Fong2015,
annote = {cout bas{\'{e}} sur une statistique de rang
dynp
consistency},
author = {Lung-Yut-Fong, A. and L{\'{e}}vy-Leduc, C. and Capp{\'{e}}, O.},
file = {:home/charles/Documents/Mendeley Desktop/Homogeneity and change-point detection tests for multivariate data using rank statistics.pdf:pdf},
journal = {Journal de la Soci{\'{e}}t{\'{e}} Fran{\c{c}}aise de Statistique},
mendeley-groups = {D{\'{e}}tection de ruptures},
number = {4},
pages = {133--162},
title = {{Homogeneity and change-point detection tests for multivariate data using rank statistics}},
volume = {156},
year = {2015}
}
@article{TRUONG2020107299,
abstract = {This article presents a selective survey of algorithms for the offline detection of multiple change points in multivariate time series. A general yet structuring methodological strategy is adopted to organize this vast body of work. More precisely, detection algorithms considered in this review are characterized by three elements: a cost function, a search method and a constraint on the number of changes. Each of those elements is described, reviewed and discussed separately. Implementations of the main algorithms described in this article are provided within a Python package called ruptures.},
author = {Truong, C. and Oudre, L. and Vayatis, N.},
journal = {Signal Processing},
keywords = {Change point detection,Segmentation,Statistical signal processing},
pages = {107299},
title = {{Selective review of offline change point detection methods}},
volume = {167},
year = {2020}
}
